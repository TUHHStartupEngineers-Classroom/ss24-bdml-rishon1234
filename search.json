[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website everytime before you want to upload changes"
  },
  {
    "objectID": "content/01_journal/02_supervised_ml.html",
    "href": "content/01_journal/02_supervised_ml.html",
    "title": "02 Supervised ML",
    "section": "",
    "text": "Load the absolute path to the data directory.\n\ndata_dir &lt;- params$data_dir\n\n\n1 Libraries\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(recipes)\nlibrary(rsample)\nlibrary(yardstick)\n\n\n\n2 Data\n\nbike_features_tbl &lt;- readRDS(\"C:/Users/risho/OneDrive/Desktop/internship_sparks/ss24-bdml-rishon1234/ML/data/Business Decisions with Machine Learning/bike_features_tbl.rds\")\nbike_features_tbl |&gt; as_tibble() |&gt; print()\n\n#&gt; # A tibble: 231 × 67\n#&gt;    bike_id model    model_year frame_material weight price category_1 category_2\n#&gt;      &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;     \n#&gt;  1    2875 Aeroad …       2020 carbon           7.6   4579 Road       Race      \n#&gt;  2    2873 Aeroad …       2020 carbon           7.27  6919 Road       Race      \n#&gt;  3    2874 Aeroad …       2020 carbon           7.1   6429 Road       Race      \n#&gt;  4    2876 Aeroad …       2020 carbon           7.73  5069 Road       Race      \n#&gt;  5    2877 Aeroad …       2020 carbon           7.83  3609 Road       Race      \n#&gt;  6    2225 Aeroad …       2019 carbon           6.8   6139 Road       Race      \n#&gt;  7    2091 Aeroad …       2019 carbon           6.8   5359 Road       Race      \n#&gt;  8    2086 Aeroad …       2021 carbon           7.6   2629 Road       Race      \n#&gt;  9    2088 Aeroad …       2020 carbon           7.3   3699 Road       Race      \n#&gt; 10    2120 Aeroad …       2020 carbon           7.2   3219 Road       Race      \n#&gt; # ℹ 221 more rows\n#&gt; # ℹ 59 more variables: category_3 &lt;chr&gt;, gender &lt;chr&gt;, url &lt;chr&gt;, Frame &lt;chr&gt;,\n#&gt; #   Fork &lt;chr&gt;, `Rear Derailleur` &lt;chr&gt;, `Front Derailleur` &lt;chr&gt;,\n#&gt; #   Cassette &lt;chr&gt;, Crank &lt;chr&gt;, `Bottom bracket` &lt;chr&gt;, `Thru Axle` &lt;chr&gt;,\n#&gt; #   Cockpit &lt;chr&gt;, Saddle &lt;chr&gt;, Seatpost &lt;chr&gt;, Pedals &lt;chr&gt;,\n#&gt; #   `Derailleur hanger` &lt;chr&gt;, Battery &lt;chr&gt;, Brake &lt;chr&gt;, `Shift Lever` &lt;chr&gt;,\n#&gt; #   Chain &lt;chr&gt;, Stem &lt;chr&gt;, Handlebar &lt;chr&gt;, Headset &lt;chr&gt;, Motor &lt;chr&gt;, …\n\n\nTransform dataset\n\nbike_features_trafo_tbl &lt;- bike_features_tbl %&gt;% \n    select(model:url, `Rear Derailleur`, `Shift Lever`) %&gt;%\n    mutate_if(is.numeric, ~replace(., is.na(.), 0)) %&gt;%\n    mutate(id = row_number()) %&gt;% \n    select(id, everything(), -url)\nbike_features_trafo_tbl |&gt; as_tibble() |&gt; print()\n\n#&gt; # A tibble: 231 × 12\n#&gt;       id model      model_year frame_material weight price category_1 category_2\n#&gt;    &lt;int&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;     \n#&gt;  1     1 Aeroad CF…       2020 carbon           7.6   4579 Road       Race      \n#&gt;  2     2 Aeroad CF…       2020 carbon           7.27  6919 Road       Race      \n#&gt;  3     3 Aeroad CF…       2020 carbon           7.1   6429 Road       Race      \n#&gt;  4     4 Aeroad CF…       2020 carbon           7.73  5069 Road       Race      \n#&gt;  5     5 Aeroad CF…       2020 carbon           7.83  3609 Road       Race      \n#&gt;  6     6 Aeroad CF…       2019 carbon           6.8   6139 Road       Race      \n#&gt;  7     7 Aeroad CF…       2019 carbon           6.8   5359 Road       Race      \n#&gt;  8     8 Aeroad CF…       2021 carbon           7.6   2629 Road       Race      \n#&gt;  9     9 Aeroad CF…       2020 carbon           7.3   3699 Road       Race      \n#&gt; 10    10 Aeroad WM…       2020 carbon           7.2   3219 Road       Race      \n#&gt; # ℹ 221 more rows\n#&gt; # ℹ 4 more variables: category_3 &lt;chr&gt;, gender &lt;chr&gt;, `Rear Derailleur` &lt;chr&gt;,\n#&gt; #   `Shift Lever` &lt;chr&gt;\n\n\nCreate training and testing dataset (Hold-out method)\n\nbike_features_trafo_tbl %&gt;% distinct(category_2) %&gt;% print()\n\n#&gt; # A tibble: 20 × 1\n#&gt;    category_2    \n#&gt;    &lt;chr&gt;         \n#&gt;  1 Race          \n#&gt;  2 Endurance     \n#&gt;  3 E-Road        \n#&gt;  4 Cyclocross    \n#&gt;  5 Triathlon Bike\n#&gt;  6 Fat Bikes     \n#&gt;  7 Cross-Country \n#&gt;  8 Adventure     \n#&gt;  9 All-Road      \n#&gt; 10 E-Gravel      \n#&gt; 11 Trail         \n#&gt; 12 E-Mountain    \n#&gt; 13 Downhill      \n#&gt; 14 Dirt Jump     \n#&gt; 15 Enduro        \n#&gt; 16 E-City        \n#&gt; 17 E-Trekking    \n#&gt; 18 E-Fitness     \n#&gt; 19 City          \n#&gt; 20 Touring\n\nset.seed(123)\nsplit &lt;- initial_split(bike_features_trafo_tbl, prop = 3/4, strata = \"category_2\")\n\nsplit %&gt;% training() %&gt;% distinct(category_2) %&gt;% print()\n\n#&gt; # A tibble: 19 × 1\n#&gt;    category_2    \n#&gt;    &lt;chr&gt;         \n#&gt;  1 Race          \n#&gt;  2 Endurance     \n#&gt;  3 Cyclocross    \n#&gt;  4 Triathlon Bike\n#&gt;  5 Fat Bikes     \n#&gt;  6 Cross-Country \n#&gt;  7 All-Road      \n#&gt;  8 E-Gravel      \n#&gt;  9 E-Mountain    \n#&gt; 10 Downhill      \n#&gt; 11 Dirt Jump     \n#&gt; 12 Enduro        \n#&gt; 13 E-City        \n#&gt; 14 E-Trekking    \n#&gt; 15 E-Fitness     \n#&gt; 16 Touring       \n#&gt; 17 City          \n#&gt; 18 Adventure     \n#&gt; 19 Trail\n\nsplit %&gt;% testing() %&gt;% distinct(category_2) %&gt;% print()\n\n#&gt; # A tibble: 15 × 1\n#&gt;    category_2    \n#&gt;    &lt;chr&gt;         \n#&gt;  1 Race          \n#&gt;  2 Endurance     \n#&gt;  3 E-Road        \n#&gt;  4 Cyclocross    \n#&gt;  5 Triathlon Bike\n#&gt;  6 Cross-Country \n#&gt;  7 Adventure     \n#&gt;  8 E-Gravel      \n#&gt;  9 All-Road      \n#&gt; 10 Trail         \n#&gt; 11 E-Mountain    \n#&gt; 12 Enduro        \n#&gt; 13 E-Trekking    \n#&gt; 14 City          \n#&gt; 15 Touring\n\ntrain_tbl &lt;- training(split)\ntest_tbl  &lt;- testing(split)\n\ntrain_tbl &lt;- train_tbl %&gt;% set_names(str_replace_all(names(train_tbl), \" |-\", \"_\"))\ntest_tbl  &lt;- test_tbl  %&gt;% set_names(str_replace_all(names(test_tbl),  \" |-\", \"_\"))\n\n\n\n3 Visualization\n\ng1 &lt;- bike_features_trafo_tbl %&gt;% \n    mutate(category_2 = as.factor(category_2) %&gt;% \n           fct_reorder(price)) %&gt;% \n    \n    ggplot(aes(category_2, price)) +\n    geom_violin() +\n    geom_jitter(width = 0.1, alpha = 0.5, color = \"#2dc6d6\") +\n    coord_flip() +\n    facet_wrap(~ frame_material) +\n    scale_y_continuous(labels = scales::dollar_format()) +\n    labs(\n        title = \"Unit Price for Each Model\",\n        y = \"\", x = \"Category 2\"\n    )\ng1\n\n#&gt; Warning: Groups with fewer than two datapoints have been dropped.\n#&gt; ℹ Set `drop = FALSE` to consider such groups for position adjustment purposes.\n#&gt; Groups with fewer than two datapoints have been dropped.\n#&gt; ℹ Set `drop = FALSE` to consider such groups for position adjustment purposes.\n#&gt; Groups with fewer than two datapoints have been dropped.\n#&gt; ℹ Set `drop = FALSE` to consider such groups for position adjustment purposes."
  },
  {
    "objectID": "content/01_journal/01_Machine_learning_fundamentals.html",
    "href": "content/01_journal/01_Machine_learning_fundamentals.html",
    "title": "01 Machine Learning Fundamentals",
    "section": "",
    "text": "Load the absolute path to the data directory.\ndata_dir &lt;- params$data_dir"
  },
  {
    "objectID": "content/01_journal/01_Machine_learning_fundamentals.html#stock-prices-standardization",
    "href": "content/01_journal/01_Machine_learning_fundamentals.html#stock-prices-standardization",
    "title": "01 Machine Learning Fundamentals",
    "section": "2.1 Stock Prices Standardization",
    "text": "2.1 Stock Prices Standardization\nStock prices (adjusted stock price) are standardized by converting them into daily returns (percent change from previous day). This is done such that the stock prices are of the same magnitude and can thus be compared. Below is the sp 500 price table shown:\n\nsp_500_prices_tbl %&gt;% glimpse()\n\n#&gt; Rows: 1,225,765\n#&gt; Columns: 8\n#&gt; $ symbol   &lt;chr&gt; \"MSFT\", \"MSFT\", \"MSFT\", \"MSFT\", \"MSFT\", \"MSFT\", \"MSFT\", \"MSFT…\n#&gt; $ date     &lt;date&gt; 2009-01-02, 2009-01-05, 2009-01-06, 2009-01-07, 2009-01-08, …\n#&gt; $ open     &lt;dbl&gt; 19.53, 20.20, 20.75, 20.19, 19.63, 20.17, 19.71, 19.52, 19.53…\n#&gt; $ high     &lt;dbl&gt; 20.40, 20.67, 21.00, 20.29, 20.19, 20.30, 19.79, 19.99, 19.68…\n#&gt; $ low      &lt;dbl&gt; 19.37, 20.06, 20.61, 19.48, 19.55, 19.41, 19.30, 19.52, 19.01…\n#&gt; $ close    &lt;dbl&gt; 20.33, 20.52, 20.76, 19.51, 20.12, 19.52, 19.47, 19.82, 19.09…\n#&gt; $ volume   &lt;dbl&gt; 50084000, 61475200, 58083400, 72709900, 70255400, 49815300, 5…\n#&gt; $ adjusted &lt;dbl&gt; 15.86624, 16.01451, 16.20183, 15.22628, 15.70234, 15.23408, 1…\n\n\n\nsp_500_daily_returns_tbl &lt;- sp_500_prices_tbl %&gt;%\n  select(symbol, date, adjusted) %&gt;%\n  filter(date &gt;= as.Date(\"2018-01-01\")) %&gt;%\n  group_by(symbol) %&gt;%\n  mutate(adjusted_lag = lag(adjusted)) %&gt;%\n  filter(!is.na(adjusted_lag)) %&gt;%\n  mutate(difference = adjusted - adjusted_lag) %&gt;%\n  mutate(pct_return = difference / adjusted_lag) %&gt;%\n  select(symbol, date, pct_return) %&gt;%\n  ungroup()\nprint(sp_500_daily_returns_tbl)\n\n#&gt; # A tibble: 141,340 × 3\n#&gt;    symbol date       pct_return\n#&gt;    &lt;chr&gt;  &lt;date&gt;          &lt;dbl&gt;\n#&gt;  1 MSFT   2018-01-03   0.00465 \n#&gt;  2 MSFT   2018-01-04   0.00880 \n#&gt;  3 MSFT   2018-01-05   0.0124  \n#&gt;  4 MSFT   2018-01-08   0.00102 \n#&gt;  5 MSFT   2018-01-09  -0.000680\n#&gt;  6 MSFT   2018-01-10  -0.00453 \n#&gt;  7 MSFT   2018-01-11   0.00296 \n#&gt;  8 MSFT   2018-01-12   0.0173  \n#&gt;  9 MSFT   2018-01-16  -0.0140  \n#&gt; 10 MSFT   2018-01-17   0.0203  \n#&gt; # ℹ 141,330 more rows"
  },
  {
    "objectID": "content/01_journal/01_Machine_learning_fundamentals.html#conversion-to-user-item-format",
    "href": "content/01_journal/01_Machine_learning_fundamentals.html#conversion-to-user-item-format",
    "title": "01 Machine Learning Fundamentals",
    "section": "2.2 Conversion to User-Item Format",
    "text": "2.2 Conversion to User-Item Format\nThe next step involves converting to a user-item format with the symbol in the first column and every other column the value of the daily returns (pct_return) for every stock at each date. The user in this case is the symbol (company), and the item in this case is the pct_return at each date.\nImporting the correct results first (just in case I was not able to complete the last step).\n\nsp_500_daily_returns_tbl &lt;- read_rds(\"C:/Users/risho/OneDrive/Desktop/internship_sparks/ss24-bdml-rishon1234/ML/data/Business Decisions with Machine Learning/sp_500_daily_returns_tbl.rds\")\nprint(sp_500_daily_returns_tbl)\n\n#&gt; # A tibble: 141,340 × 3\n#&gt;    symbol date       pct_return\n#&gt;    &lt;chr&gt;  &lt;date&gt;          &lt;dbl&gt;\n#&gt;  1 MSFT   2018-01-03   0.00465 \n#&gt;  2 MSFT   2018-01-04   0.00880 \n#&gt;  3 MSFT   2018-01-05   0.0124  \n#&gt;  4 MSFT   2018-01-08   0.00102 \n#&gt;  5 MSFT   2018-01-09  -0.000680\n#&gt;  6 MSFT   2018-01-10  -0.00453 \n#&gt;  7 MSFT   2018-01-11   0.00296 \n#&gt;  8 MSFT   2018-01-12   0.0173  \n#&gt;  9 MSFT   2018-01-16  -0.0140  \n#&gt; 10 MSFT   2018-01-17   0.0203  \n#&gt; # ℹ 141,330 more rows\n\n\nAnd the conversion follows with:\n\nstock_date_matrix_tbl &lt;- sp_500_daily_returns_tbl %&gt;%\n  spread(key = date, value = pct_return, fill = 0)\nstock_date_matrix_tbl |&gt; as_tibble() |&gt; print()\n\n#&gt; # A tibble: 502 × 283\n#&gt;    symbol `2018-01-03` `2018-01-04` `2018-01-05` `2018-01-08` `2018-01-09`\n#&gt;    &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n#&gt;  1 A          0.0254       -0.00750     0.0160        0.00215     0.0246  \n#&gt;  2 AAL       -0.0123        0.00630    -0.000380     -0.00988    -0.000959\n#&gt;  3 AAP        0.00905       0.0369      0.0106       -0.00704    -0.00808 \n#&gt;  4 AAPL      -0.000174      0.00465     0.0114       -0.00371    -0.000115\n#&gt;  5 ABBV       0.0156       -0.00570     0.0174       -0.0160      0.00754 \n#&gt;  6 ABC        0.00372      -0.00222     0.0121        0.0166      0.00640 \n#&gt;  7 ABMD       0.0173        0.0175      0.0154        0.0271      0.00943 \n#&gt;  8 ABT        0.00221      -0.00170     0.00289      -0.00288     0.00170 \n#&gt;  9 ACN        0.00462       0.0118      0.00825       0.00799     0.00333 \n#&gt; 10 ADBE       0.0188        0.0120      0.0116       -0.00162     0.00897 \n#&gt; # ℹ 492 more rows\n#&gt; # ℹ 277 more variables: `2018-01-10` &lt;dbl&gt;, `2018-01-11` &lt;dbl&gt;,\n#&gt; #   `2018-01-12` &lt;dbl&gt;, `2018-01-16` &lt;dbl&gt;, `2018-01-17` &lt;dbl&gt;,\n#&gt; #   `2018-01-18` &lt;dbl&gt;, `2018-01-19` &lt;dbl&gt;, `2018-01-22` &lt;dbl&gt;,\n#&gt; #   `2018-01-23` &lt;dbl&gt;, `2018-01-24` &lt;dbl&gt;, `2018-01-25` &lt;dbl&gt;,\n#&gt; #   `2018-01-26` &lt;dbl&gt;, `2018-01-29` &lt;dbl&gt;, `2018-01-30` &lt;dbl&gt;,\n#&gt; #   `2018-01-31` &lt;dbl&gt;, `2018-02-01` &lt;dbl&gt;, `2018-02-02` &lt;dbl&gt;, …"
  },
  {
    "objectID": "content/01_journal/01_Machine_learning_fundamentals.html#k-means-clustering",
    "href": "content/01_journal/01_Machine_learning_fundamentals.html#k-means-clustering",
    "title": "01 Machine Learning Fundamentals",
    "section": "2.3 K-Means Clustering",
    "text": "2.3 K-Means Clustering\nImporting the correct results first (just in case I was not able to complete the last step).\n\nstock_date_matrix_tbl &lt;- read_rds(\"C:/Users/risho/OneDrive/Desktop/internship_sparks/ss24-bdml-rishon1234/ML/data/Business Decisions with Machine Learning/stock_date_matrix_tbl.rds\")\nstock_date_matrix_tbl |&gt; as_tibble() |&gt; print()\n\n#&gt; # A tibble: 502 × 283\n#&gt;    symbol `2018-01-03` `2018-01-04` `2018-01-05` `2018-01-08` `2018-01-09`\n#&gt;    &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n#&gt;  1 A          0.0254       -0.00750     0.0160        0.00215     0.0246  \n#&gt;  2 AAL       -0.0123        0.00630    -0.000380     -0.00988    -0.000959\n#&gt;  3 AAP        0.00905       0.0369      0.0106       -0.00704    -0.00808 \n#&gt;  4 AAPL      -0.000174      0.00465     0.0114       -0.00371    -0.000115\n#&gt;  5 ABBV       0.0156       -0.00570     0.0174       -0.0160      0.00754 \n#&gt;  6 ABC        0.00372      -0.00222     0.0121        0.0166      0.00640 \n#&gt;  7 ABMD       0.0173        0.0175      0.0154        0.0271      0.00943 \n#&gt;  8 ABT        0.00221      -0.00170     0.00289      -0.00288     0.00170 \n#&gt;  9 ACN        0.00462       0.0118      0.00825       0.00799     0.00333 \n#&gt; 10 ADBE       0.0188        0.0120      0.0116       -0.00162     0.00897 \n#&gt; # ℹ 492 more rows\n#&gt; # ℹ 277 more variables: `2018-01-10` &lt;dbl&gt;, `2018-01-11` &lt;dbl&gt;,\n#&gt; #   `2018-01-12` &lt;dbl&gt;, `2018-01-16` &lt;dbl&gt;, `2018-01-17` &lt;dbl&gt;,\n#&gt; #   `2018-01-18` &lt;dbl&gt;, `2018-01-19` &lt;dbl&gt;, `2018-01-22` &lt;dbl&gt;,\n#&gt; #   `2018-01-23` &lt;dbl&gt;, `2018-01-24` &lt;dbl&gt;, `2018-01-25` &lt;dbl&gt;,\n#&gt; #   `2018-01-26` &lt;dbl&gt;, `2018-01-29` &lt;dbl&gt;, `2018-01-30` &lt;dbl&gt;,\n#&gt; #   `2018-01-31` &lt;dbl&gt;, `2018-02-01` &lt;dbl&gt;, `2018-02-02` &lt;dbl&gt;, …\n\n\nAnd then executing the KMeans operation:\n\n# Create kmeans_obj for 4 centers\nNUM_CENTERS &lt;- 4\nN_START = 20\n\nkmeans_obj &lt;- stock_date_matrix_tbl %&gt;%\n    select(-symbol) %&gt;%\n    kmeans(centers = NUM_CENTERS, nstart = N_START)\nprint(kmeans_obj$cluster)\n\n#&gt;   [1] 1 2 1 2 1 1 2 1 1 2 2 1 1 1 2 3 3 3 1 1 1 3 1 1 2 1 2 1 1 1 2 2 2 1 1 1 1\n#&gt;  [38] 3 2 2 2 1 1 1 4 4 1 1 1 3 1 3 2 3 2 1 3 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1\n#&gt;  [75] 1 1 1 3 1 3 1 1 1 1 1 1 3 2 1 1 1 1 1 3 1 1 1 1 3 3 1 1 1 1 1 3 1 3 1 1 1\n#&gt; [112] 4 1 1 3 1 1 2 2 1 1 1 1 1 1 4 4 3 1 1 1 1 1 1 1 1 1 1 1 3 1 1 3 1 3 3 1 4\n#&gt; [149] 1 1 2 1 1 3 1 3 1 1 1 4 3 3 3 3 1 1 3 3 2 3 1 1 3 1 4 1 2 1 4 1 3 2 1 1 1\n#&gt; [186] 1 1 4 1 1 1 1 1 1 3 4 2 1 1 1 1 3 1 1 2 2 1 2 1 1 1 1 1 4 1 1 1 1 3 1 4 4\n#&gt; [223] 1 1 1 1 1 1 4 2 1 1 3 1 1 1 3 1 1 1 2 1 2 2 1 2 2 1 1 2 1 1 3 2 1 1 1 1 1\n#&gt; [260] 1 1 1 1 1 1 1 3 1 2 3 3 2 3 4 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 2 1 3 1\n#&gt; [297] 1 2 3 3 1 1 2 3 2 1 1 3 1 1 2 1 3 1 1 1 1 3 1 4 1 4 1 2 2 1 1 1 2 2 1 4 1\n#&gt; [334] 1 3 1 2 3 1 2 1 1 4 3 1 2 1 1 2 1 1 1 3 4 1 1 1 4 1 1 1 3 3 1 1 3 1 1 1 1\n#&gt; [371] 1 3 3 1 1 3 1 3 1 1 3 4 1 1 4 2 1 2 1 1 3 1 1 2 1 1 1 1 1 1 1 1 1 1 3 1 1\n#&gt; [408] 1 1 1 3 4 3 1 2 3 3 1 3 1 1 2 1 1 2 1 1 2 3 1 3 1 1 1 1 1 1 1 1 1 2 1 1 1\n#&gt; [445] 3 2 2 2 2 1 2 2 1 3 1 1 1 1 1 1 2 1 1 2 1 1 1 4 1 3 1 2 2 3 3 1 1 1 2 3 3\n#&gt; [482] 1 1 1 3 4 1 1 1 3 2 4 3 2 4 1 1 1 1 1 1 1\n\n\nAnd using glance() to get the tot.withinss.\n\nkmeans_obj %&gt;% glance() %&gt;% print()\n\n#&gt; # A tibble: 1 × 4\n#&gt;   totss tot.withinss betweenss  iter\n#&gt;   &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n#&gt; 1  33.6         29.2      4.40     4"
  },
  {
    "objectID": "content/01_journal/01_Machine_learning_fundamentals.html#finding-optimal-k",
    "href": "content/01_journal/01_Machine_learning_fundamentals.html#finding-optimal-k",
    "title": "01 Machine Learning Fundamentals",
    "section": "2.4 Finding Optimal K",
    "text": "2.4 Finding Optimal K\n\nkmeans_mapper &lt;- function(center = 3) {\n    stock_date_matrix_tbl %&gt;%\n        select(-symbol) %&gt;%\n        kmeans(centers = center, nstart = 20)\n}\n\n\n# Use purrr to map\nkmeans_mapped_tbl &lt;- tibble(centers = 1:30) %&gt;%\n    mutate(k_means = centers %&gt;% map(kmeans_mapper)) %&gt;%\n    mutate(glance  = k_means %&gt;% map(glance))\nprint(kmeans_mapped_tbl)\n\n#&gt; # A tibble: 30 × 3\n#&gt;    centers k_means  glance          \n#&gt;      &lt;int&gt; &lt;list&gt;   &lt;list&gt;          \n#&gt;  1       1 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt;  2       2 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt;  3       3 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt;  4       4 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt;  5       5 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt;  6       6 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt;  7       7 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt;  8       8 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt;  9       9 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt; 10      10 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt; # ℹ 20 more rows\n\n\n\n# Visualize Scree Plot\nkmeans_mapped_tbl %&gt;%\n    unnest(glance) %&gt;%\n    ggplot(aes(x = centers, y = tot.withinss)) +\n    geom_point() +\n    geom_line()"
  },
  {
    "objectID": "content/01_journal/01_Machine_learning_fundamentals.html#umap-application",
    "href": "content/01_journal/01_Machine_learning_fundamentals.html#umap-application",
    "title": "01 Machine Learning Fundamentals",
    "section": "2.5 UMAP Application",
    "text": "2.5 UMAP Application\n\nk_means_mapped_tbl &lt;- read_rds(\"C:/Users/risho/OneDrive/Desktop/internship_sparks/ss24-bdml-rishon1234/ML/data/Business Decisions with Machine Learning/k_means_mapped_tbl.rds\")\nprint(k_means_mapped_tbl)\n\n#&gt; # A tibble: 30 × 3\n#&gt;    centers k_means  glance          \n#&gt;      &lt;int&gt; &lt;list&gt;   &lt;list&gt;          \n#&gt;  1       1 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt;  2       2 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt;  3       3 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt;  4       4 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt;  5       5 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt;  6       6 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt;  7       7 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt;  8       8 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt;  9       9 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt; 10      10 &lt;kmeans&gt; &lt;tibble [1 × 4]&gt;\n#&gt; # ℹ 20 more rows\n\n\n\n# Apply UMAP\numap_results &lt;- stock_date_matrix_tbl %&gt;%\n  select(-symbol) %&gt;%\n  umap()\numap_results\n\n#&gt; umap embedding of 502 items in 2 dimensions\n#&gt; object components: layout, data, knn, config\n\n\n\n# Convert umap results to tibble with symbols\numap_results_tbl &lt;- umap_results$layout %&gt;%\n    as_tibble() %&gt;%\n    bind_cols(\n      stock_date_matrix_tbl %&gt;% select(symbol)\n  )\n\n#&gt; Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n#&gt; `.name_repair` is omitted as of tibble 2.0.0.\n#&gt; ℹ Using compatibility `.name_repair`.\n\nprint(umap_results_tbl)\n\n#&gt; # A tibble: 502 × 3\n#&gt;         V1      V2 symbol\n#&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt; \n#&gt;  1 -1.56    0.148  A     \n#&gt;  2 -0.351   2.50   AAL   \n#&gt;  3 -0.0288 -1.18   AAP   \n#&gt;  4 -2.97   -0.641  AAPL  \n#&gt;  5  0.109   0.227  ABBV  \n#&gt;  6  0.550  -0.406  ABC   \n#&gt;  7 -2.92   -0.836  ABMD  \n#&gt;  8 -1.23   -0.0930 ABT   \n#&gt;  9 -1.66   -0.527  ACN   \n#&gt; 10 -2.98   -1.08   ADBE  \n#&gt; # ℹ 492 more rows\n\n\n\n# Visualize UMAP results\numap_results_tbl %&gt;%\n  ggplot(aes(x = V1, y = V2)) +\n  geom_point(alpha = 0.5) +\n  theme_tq() +\n  labs(title = \"UMAP Projection\")"
  },
  {
    "objectID": "content/01_journal/01_Machine_learning_fundamentals.html#combination-of-k-means-and-umap",
    "href": "content/01_journal/01_Machine_learning_fundamentals.html#combination-of-k-means-and-umap",
    "title": "01 Machine Learning Fundamentals",
    "section": "2.6 Combination of K-Means and UMAP",
    "text": "2.6 Combination of K-Means and UMAP\nNow the K-Means clusters and the UMAP 2D representation are being combined\nImporting the correct results first (just in case I was not able to complete the last step).\n\nk_means_mapped_tbl &lt;- read_rds(\"C:/Users/risho/OneDrive/Desktop/internship_sparks/ss24-bdml-rishon1234/ML/data/Business Decisions with Machine Learning/k_means_mapped_tbl.rds\")\numap_results_tbl   &lt;- read_rds(\"C:/Users/risho/OneDrive/Desktop/internship_sparks/ss24-bdml-rishon1234/ML/data/Business Decisions with Machine Learning/umap_results_tbl.rds\")\nprint(umap_results_tbl)\n\n#&gt; # A tibble: 502 × 3\n#&gt;         V1      V2 symbol\n#&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt; \n#&gt;  1 -0.764   1.65   A     \n#&gt;  2 -2.70    0.455  AAL   \n#&gt;  3  0.739  -0.0320 AAP   \n#&gt;  4  0.0130  3.09   AAPL  \n#&gt;  5 -0.965  -0.0193 ABBV  \n#&gt;  6 -0.506  -0.659  ABC   \n#&gt;  7  0.436   3.10   ABMD  \n#&gt;  8 -0.262   1.35   ABT   \n#&gt;  9  0.0598  1.63   ACN   \n#&gt; 10  0.570   3.43   ADBE  \n#&gt; # ℹ 492 more rows\n\n\nNow, the first 10 KMeans items are to be selected as the ScreePlot flattens beyond this one.\n\n# Get the k_means_obj from the 10th center\nk_means_obj &lt;- k_means_mapped_tbl %&gt;%\n  pull(k_means) %&gt;%\n  pluck(10)\n\nNext, the clusters from the k_means_obj with the umap_results_tbl are being combined.\n\numap_kmeans_results_tbl &lt;- k_means_obj %&gt;%\n  augment(stock_date_matrix_tbl) %&gt;%\n  select(symbol, .cluster) %&gt;%\n  left_join(umap_results_tbl, by = \"symbol\") %&gt;%\n  left_join(sp_500_index_tbl %&gt;% select(symbol, company, sector), by = \"symbol\")\nprint(umap_kmeans_results_tbl)\n\n#&gt; # A tibble: 502 × 6\n#&gt;    symbol .cluster      V1      V2 company                       sector         \n#&gt;    &lt;chr&gt;  &lt;fct&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                         &lt;chr&gt;          \n#&gt;  1 A      7        -0.764   1.65   Agilent Technologies Inc.     Health Care    \n#&gt;  2 AAL    2        -2.70    0.455  American Airlines Group Inc.  Industrials    \n#&gt;  3 AAP    10        0.739  -0.0320 Advance Auto Parts Inc.       Consumer Discr…\n#&gt;  4 AAPL   9         0.0130  3.09   Apple Inc.                    Information Te…\n#&gt;  5 ABBV   7        -0.965  -0.0193 AbbVie Inc.                   Health Care    \n#&gt;  6 ABC    5        -0.506  -0.659  AmerisourceBergen Corporation Health Care    \n#&gt;  7 ABMD   9         0.436   3.10   ABIOMED Inc.                  Health Care    \n#&gt;  8 ABT    7        -0.262   1.35   Abbott Laboratories           Health Care    \n#&gt;  9 ACN    7         0.0598  1.63   Accenture Plc Class A         Information Te…\n#&gt; 10 ADBE   9         0.570   3.43   Adobe Inc.                    Information Te…\n#&gt; # ℹ 492 more rows\n\n\nAnd finally plotting the K-Means and UMAP results.\n\n# Visualize the combined K-Means and UMAP results\nlibrary(viridis)\n\n#&gt; Loading required package: viridisLite\n\numap_kmeans_results_tbl %&gt;%\n  ggplot(aes(x = V1, y = V2, color = .cluster)) +\n  geom_point(alpha = 0.5) +\n  scale_color_manual(values = viridis_pal()(10))"
  },
  {
    "objectID": "content/01_journal/03_Automated_ML_with_H2o.html",
    "href": "content/01_journal/03_Automated_ML_with_H2o.html",
    "title": "03 Automated Machine Learning with H20",
    "section": "",
    "text": "Load the absolute path to the data directory.\n\ndata_dir &lt;- params$data_dir\n\n\n1 Libraries\n\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.5\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readxl)\nlibrary(skimr)\nlibrary(GGally)\n\n#&gt; Registered S3 method overwritten by 'GGally':\n#&gt;   method from   \n#&gt;   +.gg   ggplot2\n\n\n\n\n2 Load Data Definitions\n\ndefinitions_raw_tbl   &lt;- read_excel(file.path(\"C:/Users/risho/OneDrive/Desktop/internship_sparks/ss24-bdml-rishon1234/ML/data/Business Decisions with Machine Learning/data_definitions.xlsx\"), sheet = 1, col_names = FALSE)\n\n#&gt; New names:\n#&gt; • `` -&gt; `...1`\n#&gt; • `` -&gt; `...2`\n\ndefinitions_raw_tbl |&gt; as_tibble() |&gt; print()\n\n#&gt; # A tibble: 35 × 2\n#&gt;    ...1                    ...2             \n#&gt;    &lt;chr&gt;                   &lt;chr&gt;            \n#&gt;  1 Education               1 'Below College'\n#&gt;  2 &lt;NA&gt;                    2 'College'      \n#&gt;  3 &lt;NA&gt;                    3 'Bachelor'     \n#&gt;  4 &lt;NA&gt;                    4 'Master'       \n#&gt;  5 &lt;NA&gt;                    5 'Doctor'       \n#&gt;  6 &lt;NA&gt;                    &lt;NA&gt;             \n#&gt;  7 EnvironmentSatisfaction 1 'Low'          \n#&gt;  8 &lt;NA&gt;                    2 'Medium'       \n#&gt;  9 &lt;NA&gt;                    3 'High'         \n#&gt; 10 &lt;NA&gt;                    4 'Very High'    \n#&gt; # ℹ 25 more rows\n\n\n\n\n3 Load Employee Attrition\n\nemployee_attrition_tbl &lt;- read_csv(\"C:/Users/risho/OneDrive/Desktop/internship_sparks/ss24-bdml-rishon1234/ML/data/Business Decisions with Machine Learning/datasets-1067-1925-WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n\n#&gt; Rows: 1470 Columns: 35\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr  (9): Attrition, BusinessTravel, Department, EducationField, Gender, Job...\n#&gt; dbl (26): Age, DailyRate, DistanceFromHome, Education, EmployeeCount, Employ...\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nemployee_attrition_tbl |&gt; as_tibble() |&gt; print()\n\n#&gt; # A tibble: 1,470 × 35\n#&gt;      Age Attrition BusinessTravel    DailyRate Department       DistanceFromHome\n#&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;                 &lt;dbl&gt; &lt;chr&gt;                       &lt;dbl&gt;\n#&gt;  1    41 Yes       Travel_Rarely          1102 Sales                           1\n#&gt;  2    49 No        Travel_Frequently       279 Research & Deve…                8\n#&gt;  3    37 Yes       Travel_Rarely          1373 Research & Deve…                2\n#&gt;  4    33 No        Travel_Frequently      1392 Research & Deve…                3\n#&gt;  5    27 No        Travel_Rarely           591 Research & Deve…                2\n#&gt;  6    32 No        Travel_Frequently      1005 Research & Deve…                2\n#&gt;  7    59 No        Travel_Rarely          1324 Research & Deve…                3\n#&gt;  8    30 No        Travel_Rarely          1358 Research & Deve…               24\n#&gt;  9    38 No        Travel_Frequently       216 Research & Deve…               23\n#&gt; 10    36 No        Travel_Rarely          1299 Research & Deve…               27\n#&gt; # ℹ 1,460 more rows\n#&gt; # ℹ 29 more variables: Education &lt;dbl&gt;, EducationField &lt;chr&gt;,\n#&gt; #   EmployeeCount &lt;dbl&gt;, EmployeeNumber &lt;dbl&gt;, EnvironmentSatisfaction &lt;dbl&gt;,\n#&gt; #   Gender &lt;chr&gt;, HourlyRate &lt;dbl&gt;, JobInvolvement &lt;dbl&gt;, JobLevel &lt;dbl&gt;,\n#&gt; #   JobRole &lt;chr&gt;, JobSatisfaction &lt;dbl&gt;, MaritalStatus &lt;chr&gt;,\n#&gt; #   MonthlyIncome &lt;dbl&gt;, MonthlyRate &lt;dbl&gt;, NumCompaniesWorked &lt;dbl&gt;,\n#&gt; #   Over18 &lt;chr&gt;, OverTime &lt;chr&gt;, PercentSalaryHike &lt;dbl&gt;, …\n\n\n\n\n4 Create Visualization Method\n\nplot_ggpairs &lt;- function(data, color = NULL, density_alpha = 0.5) {\n    \n    color_expr &lt;- enquo(color)\n    \n    if (rlang::quo_is_null(color_expr)) {\n        \n        g &lt;- data %&gt;%\n            ggpairs(lower = \"blank\") \n        \n    } else {\n        \n        color_name &lt;- quo_name(color_expr)\n        \n        g &lt;- data %&gt;%\n            ggpairs(mapping = aes_string(color = color_name), \n                    lower = \"blank\", legend = 1,\n                    diag = list(continuous = wrap(\"densityDiag\", \n                                                  alpha = density_alpha))) +\n            theme(legend.position = \"bottom\")\n    }\n    \n    return(g)\n    \n}\n\n\n\n5 Visualize Feature Groups\n\n# Descriptive Features\nemployee_attrition_tbl %&gt;% \n  select(Attrition, Age, DistanceFromHome, Gender, MaritalStatus, NumCompaniesWorked, Over18) %&gt;%\n  plot_ggpairs(Attrition)\n\n#&gt; Warning: `aes_string()` was deprecated in ggplot2 3.0.0.\n#&gt; ℹ Please use tidy evaluation idioms with `aes()`.\n#&gt; ℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n\n\n\n\n\n\n\n\n# Employment Features\nemployee_attrition_tbl %&gt;% \n  select(Attrition, Department, EmployeeCount, EmployeeNumber, JobInvolvement, JobLevel, JobRole, JobSatisfaction) %&gt;%\n  plot_ggpairs(Attrition)\n\n#&gt; Warning in cor(x, y): the standard deviation is zero\n\n\n#&gt; Warning in cor(x, y): the standard deviation is zero\n#&gt; Warning in cor(x, y): the standard deviation is zero\n#&gt; Warning in cor(x, y): the standard deviation is zero\n#&gt; Warning in cor(x, y): the standard deviation is zero\n#&gt; Warning in cor(x, y): the standard deviation is zero\n#&gt; Warning in cor(x, y): the standard deviation is zero\n#&gt; Warning in cor(x, y): the standard deviation is zero\n#&gt; Warning in cor(x, y): the standard deviation is zero\n#&gt; Warning in cor(x, y): the standard deviation is zero\n#&gt; Warning in cor(x, y): the standard deviation is zero\n#&gt; Warning in cor(x, y): the standard deviation is zero\n\n\n\n\n\n\n\n\n# Compensation Features\nemployee_attrition_tbl %&gt;% \n  select(Attrition, MonthlyIncome, PercentSalaryHike, StockOptionLevel) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\n# Survery Results\nemployee_attrition_tbl %&gt;% \n  select(Attrition, EnvironmentSatisfaction, JobSatisfaction, RelationshipSatisfaction, WorkLifeBalance) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\n# Performance Data\nemployee_attrition_tbl %&gt;% \n  select(Attrition, JobInvolvement, PerformanceRating) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\n# Work-Life Features\nemployee_attrition_tbl %&gt;% \n  select(Attrition, BusinessTravel, OverTime) %&gt;%\n    plot_ggpairs(Attrition)\n\n\n\n\n\n\n\n# Training & Education\nemployee_attrition_tbl %&gt;% \n  select(Attrition, Education, EducationField, TrainingTimesLastYear) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\n# Time-Based Features\nemployee_attrition_tbl %&gt;% \n  select(Attrition, TotalWorkingYears, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager) %&gt;%\n    plot_ggpairs(Attrition)\n\n\n\n\n\n\n\n\n\n\n6 Challenge Solutions\nThe challenge question are solved based on the graphs plotted above for the feature groups.\n\n1. Compensation Features\nWhat can you deduce about the interaction between Monthly Income and Attrition?\nSolution: c. Those that are leaving have a lower Monthly Income.\n\n\n2. Compensation Features\nWhat can you deduce about the interaction between Percent Salary Hike and Attrition?\nSolution: c. Those that are leaving have lower Percent Salary Hike\nNote: However, it must be noted this distinction is not super clear as for both attrition options “yes” and “no” the mean percent salary hike is the same. Only the max value of the percent salary hike is bigger for “yes”. That’s why I decide for c).\n\n\n3. Compensation Features\nWhat can you deduce about the interaction between Stock Option Level and Attrition?\nSolution: b. Those that are staying have a higher stock option level.\n\n\n4. Survey Results\nWhat can you deduce about the interaction between Environment Satisfaction and Attrition?\nSolution: A higher proportion of those leaving have a low environment satisfaction level.\n\n\n5. Survey Results\nWhat can you deduce about the interaction between Work Life Balance and Attrition\nSolution: b. Those that are staying have a higher density of 2’s and 3’s.\n\n\n6. Performance Data\nWhat Can you deduce about the interaction between Job Involvement and Attrition?\nSolution: a. Those that are leaving have a lower density of 3’s and 4’s.\n\n\n7. Work-Life Features\nWhat can you deduce about the interaction between Over Time and Attrition?\nSolution: b. The proportion of those staying that are working Over Time are high compared to those that are not staying.\n\n\n8. Training and Education\nWhat can you deduce about the interaction between Training Times Last Year and Attrition\nSolution: b. People that leave tend to have less annual trainings.\n\n\n9. Time-Based Features\nWhat can you deduce about the interaction between Years At Company and Attrition\nSolution: b. People that leave tend to have less working years at the company.\n\n\n10. Time-Based Features\nWhat can you deduce about the interaction between Years Since Last Promotion and Attrition?\nSolution: a. Those that are leaving have more years since last promotion than those that are staying."
  },
  {
    "objectID": "content/01_journal/06_deep_learning.html",
    "href": "content/01_journal/06_deep_learning.html",
    "title": "06 Deep Learning",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .Rmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "content/01_journal/06_deep_learning.html#second-level-header",
    "href": "content/01_journal/06_deep_learning.html#second-level-header",
    "title": "06 Deep Learning",
    "section": "1.1 Second level header",
    "text": "1.1 Second level header\nYou can add more headers by adding more hashtags. These won’t be put into the table of contents\n\nthird level header\nHere’s an even lower level header"
  }
]