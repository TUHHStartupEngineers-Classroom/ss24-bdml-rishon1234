{
  "hash": "471e5d1ba336414bc669a686900cca6e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"05 LIME\"\ndate: \"2024-06-22\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    df_print: paged\n    collapsed: false\n    number_sections: true\n    toc_depth: 3\n    #code_folding: hide\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(h2o)\nlibrary(recipes)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(lime)\nlibrary(rsample)\n\nproduct_data <- read_csv(\"C:/Users/risho/OneDrive/Desktop/internship_sparks/ss24-bdml-rishon1234/ML/data/Business Decisions with Machine Learning/product_backorders.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 19053 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\ndbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nproduct_data2 <- product_data %>% \n  mutate(\n    product_backorder = went_on_backorder %>% str_to_lower() %>% str_detect(\"yes\") %>% as.numeric()\n  ) %>% \n  select(-c(went_on_backorder))\nglimpse(product_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 19,053\nColumns: 23\n$ sku               <dbl> 1113121, 1113268, 1113874, 1114222, 1114823, 1115453…\n$ national_inv      <dbl> 0, 0, 20, 0, 0, 55, -34, 4, 2, -7, 1, 2, 0, 0, 0, 0,…\n$ lead_time         <dbl> 8, 8, 2, 8, 12, 8, 8, 9, 8, 8, 8, 8, 12, 2, 12, 4, 2…\n$ in_transit_qty    <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0…\n$ forecast_3_month  <dbl> 6, 2, 45, 9, 31, 216, 120, 43, 4, 56, 2, 5, 5, 54, 4…\n$ forecast_6_month  <dbl> 6, 3, 99, 14, 31, 360, 240, 67, 6, 96, 4, 9, 6, 72, …\n$ forecast_9_month  <dbl> 6, 4, 153, 21, 31, 492, 240, 115, 9, 112, 6, 13, 9, …\n$ sales_1_month     <dbl> 0, 1, 16, 5, 7, 30, 83, 5, 1, 13, 0, 1, 0, 0, 1, 0, …\n$ sales_3_month     <dbl> 4, 2, 42, 17, 15, 108, 122, 22, 5, 30, 2, 5, 4, 0, 3…\n$ sales_6_month     <dbl> 9, 3, 80, 36, 33, 275, 144, 40, 6, 56, 3, 8, 5, 0, 4…\n$ sales_9_month     <dbl> 12, 3, 111, 43, 47, 340, 165, 58, 9, 76, 4, 11, 6, 0…\n$ min_bank          <dbl> 0, 0, 10, 0, 2, 51, 33, 4, 2, 0, 0, 0, 3, 4, 0, 0, 0…\n$ potential_issue   <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ pieces_past_due   <dbl> 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ perf_6_month_avg  <dbl> 0.90, 0.96, 0.81, 0.96, 0.98, 0.00, 1.00, 0.69, 1.00…\n$ perf_12_month_avg <dbl> 0.89, 0.97, 0.88, 0.98, 0.98, 0.00, 0.97, 0.68, 0.95…\n$ local_bo_qty      <dbl> 0, 0, 0, 0, 0, 0, 34, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, …\n$ deck_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ oe_constraint     <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ ppap_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No…\n$ stop_auto_buy     <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n$ rev_stop          <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ went_on_backorder <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n```\n\n\n:::\n\n```{.r .cell-code}\nsplit_obj<- initial_split(product_data2, prop = 0.75)\ntrain_tbl<- training(split_obj)\ntest_tbl<- testing(split_obj)\n\nrecipe_obj <- recipe(product_backorder ~., data = train_tbl) %>% \n  step_zv(all_predictors()) %>% \n  step_dummy(all_nominal(),-all_outcomes()) %>%\n  prep()\nsplit_obj<- initial_split(product_data2, prop = 0.75)\ntrain_tbl<- training(split_obj)\ntest_tbl<- testing(split_obj)\n\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nH2O is not running yet, starting it now...\n\nNote:  In case of errors look at the following log files:\n    C:\\Users\\risho\\AppData\\Local\\Temp\\RtmpwdL0pP\\file8a14ac911e7/h2o_risho_started_from_r.out\n    C:\\Users\\risho\\AppData\\Local\\Temp\\RtmpwdL0pP\\file8a14578c4bce/h2o_risho_started_from_r.err\n\n\nStarting H2O JVM and connecting:  Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         3 seconds 280 milliseconds \n    H2O cluster timezone:       Europe/Berlin \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.44.0.3 \n    H2O cluster version age:    6 months and 3 days \n    H2O cluster name:           H2O_started_from_R_risho_uqp254 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   1.91 GB \n    H2O cluster total cores:    12 \n    H2O cluster allowed cores:  12 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.4.0 (2024-04-24 ucrt) \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in h2o.clusterInfo(): \nYour H2O cluster version is (6 months and 3 days) old. There may be a newer version available.\nPlease download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n```\n\n\n:::\n\n```{.r .cell-code}\nautoml_leader <- h2o.loadModel(\"C:/Users/risho/OneDrive/Desktop/internship_sparks/ss24-bdml-rishon1234/ML/StackedEnsemble_AllModels_AutoML_20220603_533865/StackedEnsemble_AllModels_3_AutoML_1_20240622_142532\")\nautoml_leader\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel Details:\n==============\n\nH2ORegressionModel: stackedensemble\nModel ID:  StackedEnsemble_AllModels_3_AutoML_1_20240622_142532 \nModel Summary for Stacked Ensemble: \n                                         key            value\n1                          Stacking strategy cross_validation\n2       Number of base models (used / total)            19/50\n3           # GBM base models (used / total)            17/42\n4           # DRF base models (used / total)              2/2\n5  # DeepLearning base models (used / total)              0/5\n6           # GLM base models (used / total)              0/1\n7                      Metalearner algorithm              GLM\n8         Metalearner fold assignment scheme           Random\n9                         Metalearner nfolds                5\n10                   Metalearner fold_column               NA\n11        Custom metalearner hyperparameters             None\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on training data. **\n\nMSE:  0.01822598\nRMSE:  0.1350036\nMAE:  0.06575185\nRMSLE:  0.09474208\nMean Residual Deviance :  0.01822598\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on validation data. **\n\nMSE:  0.05120148\nRMSE:  0.2262774\nMAE:  0.1102032\nRMSLE:  0.1590233\nMean Residual Deviance :  0.05120148\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  0.05040252\nRMSE:  0.2245051\nMAE:  0.1120714\nRMSLE:  0.1578221\nMean Residual Deviance :  0.05040252\n\n\nCross-Validation Metrics Summary: \n                             mean        sd cv_1_valid cv_2_valid cv_3_valid\nmae                      0.112069  0.003868   0.110514   0.118646   0.111860\nmean_residual_deviance   0.050346  0.003496   0.050188   0.055389   0.051883\nmse                      0.050346  0.003496   0.050188   0.055389   0.051883\nnull_deviance          224.017940 12.613392 220.105120 244.018360 227.994700\nr2                       0.517080  0.016213   0.498813   0.511007   0.507770\nresidual_deviance      108.197270  8.415395 110.263910 119.086914 112.222010\nrmse                     0.224273  0.007750   0.224028   0.235349   0.227777\nrmsle                    0.157645  0.004187   0.157953   0.164196   0.157973\n                       cv_4_valid cv_5_valid\nmae                      0.108535   0.110791\nmean_residual_deviance   0.046653   0.047618\nmse                      0.046653   0.047618\nnull_deviance          215.392840 212.578670\nr2                       0.537650   0.530161\nresidual_deviance       99.557594  99.855950\nrmse                     0.215993   0.218217\nrmsle                    0.153275   0.154830\n```\n\n\n:::\n\n```{.r .cell-code}\npredictions_tbl <- automl_leader %>% \n  h2o.predict(newdata = as.h2o(test_tbl)) %>%\n  as.tibble() %>%\n  bind_cols(\n    test_tbl %>%\n      select(everything())\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: `as.tibble()` was deprecated in tibble 2.0.0.\nℹ Please use `as_tibble()` instead.\nℹ The signature and semantics have changed, see `?as_tibble`.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\npredictions_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4,764 × 24\n   predict     sku national_inv lead_time in_transit_qty forecast_3_month\n     <dbl>   <dbl>        <dbl>     <dbl>          <dbl>            <dbl>\n 1   0.553 1113121            0         8              1                6\n 2   0.858 1115620          -34         8              0              120\n 3   0.844 1116868           -7         8              0               56\n 4   0.749 1117565            2         8              0                5\n 5   0.825 1118984            0        12              0                4\n 6   0.664 1120320            1         2              1                3\n 7   0.682 1120866            4        12              0                0\n 8   0.496 1122461            0         2              0                5\n 9   0.824 1122487            1         8              0               10\n10   0.661 1124321            0        12              0              163\n# ℹ 4,754 more rows\n# ℹ 18 more variables: forecast_6_month <dbl>, forecast_9_month <dbl>,\n#   sales_1_month <dbl>, sales_3_month <dbl>, sales_6_month <dbl>,\n#   sales_9_month <dbl>, min_bank <dbl>, potential_issue <chr>,\n#   pieces_past_due <dbl>, perf_6_month_avg <dbl>, perf_12_month_avg <dbl>,\n#   local_bo_qty <dbl>, deck_risk <chr>, oe_constraint <chr>, ppap_risk <chr>,\n#   stop_auto_buy <chr>, rev_stop <chr>, product_backorder <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(train_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      sku           national_inv        lead_time      in_transit_qty    \n Min.   :1111620   Min.   : -1163.0   Min.   : 0.000   Min.   :    0.00  \n 1st Qu.:1512342   1st Qu.:     3.0   1st Qu.: 4.000   1st Qu.:    0.00  \n Median :1926234   Median :    12.0   Median : 8.000   Median :    0.00  \n Mean   :2061720   Mean   :   347.8   Mean   : 7.671   Mean   :   40.76  \n 3rd Qu.:2829444   3rd Qu.:    62.0   3rd Qu.: 8.000   3rd Qu.:    0.00  \n Max.   :3284775   Max.   :346702.0   Max.   :52.000   Max.   :68955.00  \n                                      NA's   :823                        \n forecast_3_month   forecast_6_month   forecast_9_month    sales_1_month      \n Min.   :     0.0   Min.   :     0.0   Min.   :      0.0   Min.   :     0.00  \n 1st Qu.:     0.0   1st Qu.:     0.0   1st Qu.:      0.0   1st Qu.:     0.00  \n Median :     0.0   Median :     0.0   Median :      0.0   Median :     0.00  \n Mean   :   174.9   Mean   :   337.3   Mean   :    493.3   Mean   :    60.06  \n 3rd Qu.:     9.0   3rd Qu.:    20.0   3rd Qu.:     30.0   3rd Qu.:     5.00  \n Max.   :479808.0   Max.   :967776.0   Max.   :1418208.0   Max.   :186451.00  \n                                                                              \n sales_3_month      sales_6_month       sales_9_month          min_bank       \n Min.   :     0.0   Min.   :      0.0   Min.   :      0.0   Min.   :    0.00  \n 1st Qu.:     0.0   1st Qu.:      0.0   1st Qu.:      0.0   1st Qu.:    0.00  \n Median :     2.0   Median :      3.0   Median :      5.0   Median :    0.00  \n Mean   :   178.8   Mean   :    351.5   Mean   :    529.7   Mean   :   50.95  \n 3rd Qu.:    16.0   3rd Qu.:     32.0   3rd Qu.:     47.0   3rd Qu.:    3.00  \n Max.   :550609.0   Max.   :1136154.0   Max.   :1759152.0   Max.   :85584.00  \n                                                                              \n potential_issue    pieces_past_due    perf_6_month_avg perf_12_month_avg\n Length:14289       Min.   :   0.000   Min.   :-99.00   Min.   :-99.00   \n Class :character   1st Qu.:   0.000   1st Qu.:  0.62   1st Qu.:  0.64   \n Mode  :character   Median :   0.000   Median :  0.82   Median :  0.80   \n                    Mean   :   1.624   Mean   : -6.62   Mean   : -6.15   \n                    3rd Qu.:   0.000   3rd Qu.:  0.96   3rd Qu.:  0.95   \n                    Max.   :4200.000   Max.   :  1.00   Max.   :  1.00   \n                                                                         \n  local_bo_qty        deck_risk         oe_constraint       ppap_risk        \n Min.   :   0.0000   Length:14289       Length:14289       Length:14289      \n 1st Qu.:   0.0000   Class :character   Class :character   Class :character  \n Median :   0.0000   Mode  :character   Mode  :character   Mode  :character  \n Mean   :   0.7353                                                           \n 3rd Qu.:   0.0000                                                           \n Max.   :1370.0000                                                           \n                                                                             \n stop_auto_buy        rev_stop         product_backorder\n Length:14289       Length:14289       Min.   :0.0000   \n Class :character   Class :character   1st Qu.:0.0000   \n Mode  :character   Mode  :character   Median :0.0000   \n                                       Mean   :0.1189   \n                                       3rd Qu.:0.0000   \n                                       Max.   :1.0000   \n                                                        \n```\n\n\n:::\n\n```{.r .cell-code}\n## Original plot_features()\n\n# explanation %>% \n#   as.tibble()\n#   \n# case_1 <- explanation %>%\n#     filter(case == 1)\n# \n# case_1 %>%\n#     plot_features()\n# You will need at least the layers geom_col() and coord_flip().\nexplainer <- train_tbl %>%\n  select(-product_backorder) %>%\n  lime(\n    model           = automl_leader,\n    bin_continuous  = TRUE,\n    n_bins          = 4,\n    quantile_bins   = TRUE\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: in_transit_qty does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: pieces_past_due does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: local_bo_qty does not contain enough variance to use quantile binning.\nUsing standard binning instead.\n```\n\n\n:::\n\n```{.r .cell-code}\nexplainer\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$model\nModel Details:\n==============\n\nH2ORegressionModel: stackedensemble\nModel ID:  StackedEnsemble_AllModels_3_AutoML_1_20240622_142532 \nModel Summary for Stacked Ensemble: \n                                         key            value\n1                          Stacking strategy cross_validation\n2       Number of base models (used / total)            19/50\n3           # GBM base models (used / total)            17/42\n4           # DRF base models (used / total)              2/2\n5  # DeepLearning base models (used / total)              0/5\n6           # GLM base models (used / total)              0/1\n7                      Metalearner algorithm              GLM\n8         Metalearner fold assignment scheme           Random\n9                         Metalearner nfolds                5\n10                   Metalearner fold_column               NA\n11        Custom metalearner hyperparameters             None\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on training data. **\n\nMSE:  0.01822598\nRMSE:  0.1350036\nMAE:  0.06575185\nRMSLE:  0.09474208\nMean Residual Deviance :  0.01822598\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on validation data. **\n\nMSE:  0.05120148\nRMSE:  0.2262774\nMAE:  0.1102032\nRMSLE:  0.1590233\nMean Residual Deviance :  0.05120148\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  0.05040252\nRMSE:  0.2245051\nMAE:  0.1120714\nRMSLE:  0.1578221\nMean Residual Deviance :  0.05040252\n\n\nCross-Validation Metrics Summary: \n                             mean        sd cv_1_valid cv_2_valid cv_3_valid\nmae                      0.112069  0.003868   0.110514   0.118646   0.111860\nmean_residual_deviance   0.050346  0.003496   0.050188   0.055389   0.051883\nmse                      0.050346  0.003496   0.050188   0.055389   0.051883\nnull_deviance          224.017940 12.613392 220.105120 244.018360 227.994700\nr2                       0.517080  0.016213   0.498813   0.511007   0.507770\nresidual_deviance      108.197270  8.415395 110.263910 119.086914 112.222010\nrmse                     0.224273  0.007750   0.224028   0.235349   0.227777\nrmsle                    0.157645  0.004187   0.157953   0.164196   0.157973\n                       cv_4_valid cv_5_valid\nmae                      0.108535   0.110791\nmean_residual_deviance   0.046653   0.047618\nmse                      0.046653   0.047618\nnull_deviance          215.392840 212.578670\nr2                       0.537650   0.530161\nresidual_deviance       99.557594  99.855950\nrmse                     0.215993   0.218217\nrmsle                    0.153275   0.154830\n\n$preprocess\nfunction (x) \nx\n<bytecode: 0x000002853a318998>\n<environment: 0x000002853a31ae68>\n\n$bin_continuous\n[1] TRUE\n\n$n_bins\n[1] 4\n\n$quantile_bins\n[1] TRUE\n\n$use_density\n[1] TRUE\n\n$feature_type\n              sku      national_inv         lead_time    in_transit_qty \n        \"numeric\"         \"numeric\"         \"numeric\"         \"numeric\" \n forecast_3_month  forecast_6_month  forecast_9_month     sales_1_month \n        \"numeric\"         \"numeric\"         \"numeric\"         \"numeric\" \n    sales_3_month     sales_6_month     sales_9_month          min_bank \n        \"numeric\"         \"numeric\"         \"numeric\"         \"numeric\" \n  potential_issue   pieces_past_due  perf_6_month_avg perf_12_month_avg \n      \"character\"         \"numeric\"         \"numeric\"         \"numeric\" \n     local_bo_qty         deck_risk     oe_constraint         ppap_risk \n        \"numeric\"       \"character\"       \"character\"       \"character\" \n    stop_auto_buy          rev_stop \n      \"character\"       \"character\" \n\n$bin_cuts\n$bin_cuts$sku\n     0%     25%     50%     75%    100% \n1111620 1512342 1926234 2829444 3284775 \n\n$bin_cuts$national_inv\n    0%    25%    50%    75%   100% \n -1163      3     12     62 346702 \n\n$bin_cuts$lead_time\n  0%  25%  50% 100% \n   0    4    8   52 \n\n$bin_cuts$in_transit_qty\n[1]     0.00 17238.75 34477.50 51716.25 68955.00\n\n$bin_cuts$forecast_3_month\n    0%    75%   100% \n     0      9 479808 \n\n$bin_cuts$forecast_6_month\n    0%    75%   100% \n     0     20 967776 \n\n$bin_cuts$forecast_9_month\n     0%     75%    100% \n      0      30 1418208 \n\n$bin_cuts$sales_1_month\n    0%    75%   100% \n     0      5 186451 \n\n$bin_cuts$sales_3_month\n    0%    50%    75%   100% \n     0      2     16 550609 \n\n$bin_cuts$sales_6_month\n     0%     50%     75%    100% \n      0       3      32 1136154 \n\n$bin_cuts$sales_9_month\n     0%     50%     75%    100% \n      0       5      47 1759152 \n\n$bin_cuts$min_bank\n   0%   75%  100% \n    0     3 85584 \n\n$bin_cuts$potential_issue\nNULL\n\n$bin_cuts$pieces_past_due\n[1]    0 1050 2100 3150 4200\n\n$bin_cuts$perf_6_month_avg\n    0%    25%    50%    75%   100% \n-99.00   0.62   0.82   0.96   1.00 \n\n$bin_cuts$perf_12_month_avg\n    0%    25%    50%    75%   100% \n-99.00   0.64   0.80   0.95   1.00 \n\n$bin_cuts$local_bo_qty\n[1]    0.0  342.5  685.0 1027.5 1370.0\n\n$bin_cuts$deck_risk\nNULL\n\n$bin_cuts$oe_constraint\nNULL\n\n$bin_cuts$ppap_risk\nNULL\n\n$bin_cuts$stop_auto_buy\nNULL\n\n$bin_cuts$rev_stop\nNULL\n\n\n$feature_distribution\n$feature_distribution$sku\n\n        1         2         3         4 \n0.2500525 0.2499825 0.2499825 0.2499825 \n\n$feature_distribution$national_inv\n\n        1         2         3         4 \n0.2716075 0.2448037 0.2343761 0.2492127 \n\n$feature_distribution$lead_time\n\n        1         2         3 \n0.3023305 0.4126251 0.2274477 \n\n$feature_distribution$in_transit_qty\n\n           1            2            3            4 \n0.9996500805 0.0002099517 0.0000699839 0.0000699839 \n\n$feature_distribution$forecast_3_month\n\n        1         2 \n0.7544265 0.2455735 \n\n$feature_distribution$forecast_6_month\n\n       1        2 \n0.756596 0.243404 \n\n$feature_distribution$forecast_9_month\n\n        1         2 \n0.7558262 0.2441738 \n\n$feature_distribution$sales_1_month\n\n        1         2 \n0.7619148 0.2380852 \n\n$feature_distribution$sales_3_month\n\n        1         2         3 \n0.5510533 0.2023235 0.2466233 \n\n$feature_distribution$sales_6_month\n\n        1         2         3 \n0.5084331 0.2441738 0.2473931 \n\n$feature_distribution$sales_9_month\n\n        1         2         3 \n0.5138218 0.2380852 0.2480929 \n\n$feature_distribution$min_bank\n\n        1         2 \n0.7582756 0.2417244 \n\n$feature_distribution$potential_issue\n\n          No          Yes \n0.9990902093 0.0009097907 \n\n$feature_distribution$pieces_past_due\n\n           1            4 \n0.9998600322 0.0001399678 \n\n$feature_distribution$perf_6_month_avg\n\n        1         2         3         4 \n0.2502624 0.2697879 0.2307369 0.2492127 \n\n$feature_distribution$perf_12_month_avg\n\n        1         2         3         4 \n0.2509623 0.2557912 0.2611099 0.2321366 \n\n$feature_distribution$local_bo_qty\n\n           1            2            3            4 \n0.9995800966 0.0002099517 0.0000699839 0.0001399678 \n\n$feature_distribution$deck_risk\n\n      No      Yes \n0.778291 0.221709 \n\n$feature_distribution$oe_constraint\n\n          No          Yes \n0.9998600322 0.0001399678 \n\n$feature_distribution$ppap_risk\n\n       No       Yes \n0.8778081 0.1221919 \n\n$feature_distribution$stop_auto_buy\n\n        No        Yes \n0.03492197 0.96507803 \n\n$feature_distribution$rev_stop\n\n          No          Yes \n0.9994401288 0.0005598712 \n\n\nattr(,\"class\")\n[1] \"data_frame_explainer\" \"explainer\"            \"list\"                \n```\n\n\n:::\n\n```{.r .cell-code}\nexplanation <- test_tbl %>%\n  slice(1) %>%\n  select(-product_backorder) %>%\n  lime::explain(\n    \n    # Pass our explainer object\n    explainer = explainer,\n    # Because it is a binary classification model: 1\n    n_labels   = 1,\n    # number of features to be returned\n    n_features = 8,\n    # number of localized linear models\n    n_permutations = 5000,\n    # Let's start with 1\n    kernel_width   = 1\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in explain.data.frame(., explainer = explainer, n_labels = 1,\nn_features = 8, : \"labels\" and \"n_labels\" arguments are ignored when explaining\nregression models\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nexplanation\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 × 11\n  model_type case  model_r2 model_intercept model_prediction feature         \n  <chr>      <chr>    <dbl>           <dbl>            <dbl> <chr>           \n1 regression 1        0.476           0.555            0.449 national_inv    \n2 regression 1        0.476           0.555            0.449 oe_constraint   \n3 regression 1        0.476           0.555            0.449 forecast_3_month\n4 regression 1        0.476           0.555            0.449 sku             \n5 regression 1        0.476           0.555            0.449 rev_stop        \n6 regression 1        0.476           0.555            0.449 perf_6_month_avg\n7 regression 1        0.476           0.555            0.449 pieces_past_due \n8 regression 1        0.476           0.555            0.449 local_bo_qty    \n# ℹ 5 more variables: feature_value <chr>, feature_weight <dbl>,\n#   feature_desc <chr>, data <list>, prediction <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\ng <- plot_features(explanation = explanation, ncol = 1, cases = 1)\ng\n```\n\n::: {.cell-output-display}\n![](05_lime_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n## Bonus Objectives:\n\nexplanation_multi <- test_tbl %>%\n  slice(1:20) %>%\n  select(-product_backorder) %>%\n  lime::explain(\n    explainer = explainer,\n    n_labels   = 1,\n    n_features = 8,\n    n_permutations = 5000,\n    kernel_width   = 0.5\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in explain.data.frame(., explainer = explainer, n_labels = 1,\nn_features = 8, : \"labels\" and \"n_labels\" arguments are ignored when explaining\nregression models\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nexplanation_multi %>%\n  as.tibble()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 160 × 11\n   model_type case  model_r2 model_intercept model_prediction feature         \n   <chr>      <chr>    <dbl>           <dbl>            <dbl> <chr>           \n 1 regression 1        0.514           0.754            0.462 national_inv    \n 2 regression 1        0.514           0.754            0.462 forecast_3_month\n 3 regression 1        0.514           0.754            0.462 in_transit_qty  \n 4 regression 1        0.514           0.754            0.462 sku             \n 5 regression 1        0.514           0.754            0.462 potential_issue \n 6 regression 1        0.514           0.754            0.462 forecast_6_month\n 7 regression 1        0.514           0.754            0.462 rev_stop        \n 8 regression 1        0.514           0.754            0.462 min_bank        \n 9 regression 2        0.499           0.350            0.627 national_inv    \n10 regression 2        0.499           0.350            0.627 forecast_3_month\n# ℹ 150 more rows\n# ℹ 5 more variables: feature_value <chr>, feature_weight <dbl>,\n#   feature_desc <chr>, data <list>, prediction <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\nplot_explanations(explanation_multi)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Unknown or uninitialised column: `label`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](05_lime_files/figure-html/unnamed-chunk-1-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Part 2: Recreate plot_explanations():\n## Customized plot_features()\n\ntheme_lime <- function(...) {\n  theme_minimal() +\n    theme(\n      strip.text = element_text(face = 'bold', size = 9),\n      plot.margin = margin(15, 15, 15, 15),\n      legend.background = element_blank(),\n      legend.key = element_blank(),\n      panel.grid.major.y = element_blank(),\n      panel.grid.minor.y = element_blank(),\n      axis.ticks = element_blank(),\n      legend.position = 'bottom',\n      panel.spacing.y = unit(15, 'pt'),\n      strip.text.x = element_text(margin = margin(t = 2, b = 2), hjust = 0),\n      axis.title.y = element_text(margin = margin(r = 10)),\n      axis.title.x = element_text(margin = margin(t = 10)),\n      panel.background = element_rect(fill   = \"transparent\"),\n      panel.border     = element_rect(color = \"black\", fill = NA, size = 0.5),\n      panel.grid.major = element_line(color = \"grey\", size = 0.333),\n      ...\n    )\n}\n\nplot_explanations_customized <- function(explanation, ...) {\n  num_cases <- unique(suppressWarnings(as.numeric(explanation$case)))\n  if (!anyNA(num_cases)) {\n    explanation$case <- factor(explanation$case, levels = as.character(sort(num_cases)))\n  }\n  explanation$feature_desc <- factor(\n    explanation$feature_desc,\n    levels = rev(unique(explanation$feature_desc[order(explanation$feature, explanation$feature_value)]))\n  )\n  \n  \n  p <- ggplot(explanation, aes_(~case, ~feature_desc),show.legend=TRUE) +\n    geom_tile(aes_(fill = ~feature_weight)) +\n    scale_x_discrete('Case', expand = c(0, 0)) +\n    scale_y_discrete('Feature', expand = c(0, 0)) +\n    scale_fill_gradient2('Feature\\nweight', low = 'firebrick', mid = '#f7f7f7', high = 'steelblue') +\n    theme_lime() +\n    theme(panel.border = element_rect(fill = NA, colour = 'grey60', size = 1),\n          panel.grid = element_blank(),\n          legend.position = 'right',\n          axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))\n  if (is.null(explanation$label)) {\n    p\n  } else {\n    p + facet_wrap(~label, ...)\n  }\n}\n\n\n\nplot_explanations_customized(explanation = explanation, ncol = 1, cases = 1)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: `aes_()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Unknown or uninitialised column: `label`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](05_lime_files/figure-html/unnamed-chunk-1-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_explanations_customized(explanation_multi)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Unknown or uninitialised column: `label`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](05_lime_files/figure-html/unnamed-chunk-1-4.png){width=672}\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}