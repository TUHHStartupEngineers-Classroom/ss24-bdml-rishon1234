{
  "hash": "60fadcb64e19990dec6e476621fa660b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"05 LIME\"\ndate: \"2022-06-12\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    df_print: paged\n    collapsed: false\n    number_sections: true\n    toc_depth: 3\n    #code_folding: hide\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(h2o)\nlibrary(recipes)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(lime)\nlibrary(rsample)\n\nproduct_data <- read_csv(\"C:/Users/risho/OneDrive/Desktop/internship_sparks/ss24-bdml-rishon1234/ML/data/Business Decisions with Machine Learning/product_backorders.csv\")\nproduct_data2 <- product_data %>% \n  mutate(\n    product_backorder = went_on_backorder %>% str_to_lower() %>% str_detect(\"yes\") %>% as.numeric()\n  ) %>% \n  select(-c(went_on_backorder))\nglimpse(product_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 19,053\nColumns: 23\n$ sku               <dbl> 1113121, 1113268, 1113874, 1114222, 1114823, 1115453…\n$ national_inv      <dbl> 0, 0, 20, 0, 0, 55, -34, 4, 2, -7, 1, 2, 0, 0, 0, 0,…\n$ lead_time         <dbl> 8, 8, 2, 8, 12, 8, 8, 9, 8, 8, 8, 8, 12, 2, 12, 4, 2…\n$ in_transit_qty    <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0…\n$ forecast_3_month  <dbl> 6, 2, 45, 9, 31, 216, 120, 43, 4, 56, 2, 5, 5, 54, 4…\n$ forecast_6_month  <dbl> 6, 3, 99, 14, 31, 360, 240, 67, 6, 96, 4, 9, 6, 72, …\n$ forecast_9_month  <dbl> 6, 4, 153, 21, 31, 492, 240, 115, 9, 112, 6, 13, 9, …\n$ sales_1_month     <dbl> 0, 1, 16, 5, 7, 30, 83, 5, 1, 13, 0, 1, 0, 0, 1, 0, …\n$ sales_3_month     <dbl> 4, 2, 42, 17, 15, 108, 122, 22, 5, 30, 2, 5, 4, 0, 3…\n$ sales_6_month     <dbl> 9, 3, 80, 36, 33, 275, 144, 40, 6, 56, 3, 8, 5, 0, 4…\n$ sales_9_month     <dbl> 12, 3, 111, 43, 47, 340, 165, 58, 9, 76, 4, 11, 6, 0…\n$ min_bank          <dbl> 0, 0, 10, 0, 2, 51, 33, 4, 2, 0, 0, 0, 3, 4, 0, 0, 0…\n$ potential_issue   <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ pieces_past_due   <dbl> 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ perf_6_month_avg  <dbl> 0.90, 0.96, 0.81, 0.96, 0.98, 0.00, 1.00, 0.69, 1.00…\n$ perf_12_month_avg <dbl> 0.89, 0.97, 0.88, 0.98, 0.98, 0.00, 0.97, 0.68, 0.95…\n$ local_bo_qty      <dbl> 0, 0, 0, 0, 0, 0, 34, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, …\n$ deck_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ oe_constraint     <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ ppap_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No…\n$ stop_auto_buy     <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n$ rev_stop          <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ went_on_backorder <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n```\n\n\n:::\n\n```{.r .cell-code}\nsplit_obj<- initial_split(product_data2, prop = 0.75)\ntrain_tbl<- training(split_obj)\ntest_tbl<- testing(split_obj)\n\nrecipe_obj <- recipe(product_backorder ~., data = train_tbl) %>% \n  step_zv(all_predictors()) %>% \n  step_dummy(all_nominal(),-all_outcomes()) %>%\n  prep()\nsplit_obj<- initial_split(product_data2, prop = 0.75)\ntrain_tbl<- training(split_obj)\ntest_tbl<- testing(split_obj)\n\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         2 hours 29 minutes \n    H2O cluster timezone:       Europe/Berlin \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.44.0.3 \n    H2O cluster version age:    6 months and 2 days \n    H2O cluster name:           H2O_started_from_R_risho_wae888 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   0.86 GB \n    H2O cluster total cores:    12 \n    H2O cluster allowed cores:  12 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.4.0 (2024-04-24 ucrt) \n```\n\n\n:::\n\n```{.r .cell-code}\nautoml_leader <- h2o.loadModel(\"C:/Users/risho/OneDrive/Desktop/internship_sparks/ss24-bdml-rishon1234/ML/StackedEnsemble_AllModels_AutoML_20220603_533865/StackedEnsemble_AllModels_3_AutoML_1_20240622_142532\")\nautoml_leader\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel Details:\n==============\n\nH2ORegressionModel: stackedensemble\nModel ID:  StackedEnsemble_AllModels_3_AutoML_1_20240622_142532 \nModel Summary for Stacked Ensemble: \n                                         key            value\n1                          Stacking strategy cross_validation\n2       Number of base models (used / total)            19/50\n3           # GBM base models (used / total)            17/42\n4           # DRF base models (used / total)              2/2\n5  # DeepLearning base models (used / total)              0/5\n6           # GLM base models (used / total)              0/1\n7                      Metalearner algorithm              GLM\n8         Metalearner fold assignment scheme           Random\n9                         Metalearner nfolds                5\n10                   Metalearner fold_column               NA\n11        Custom metalearner hyperparameters             None\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on training data. **\n\nMSE:  0.01822598\nRMSE:  0.1350036\nMAE:  0.06575185\nRMSLE:  0.09474208\nMean Residual Deviance :  0.01822598\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on validation data. **\n\nMSE:  0.05120148\nRMSE:  0.2262774\nMAE:  0.1102032\nRMSLE:  0.1590233\nMean Residual Deviance :  0.05120148\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  0.05040252\nRMSE:  0.2245051\nMAE:  0.1120714\nRMSLE:  0.1578221\nMean Residual Deviance :  0.05040252\n\n\nCross-Validation Metrics Summary: \n                             mean        sd cv_1_valid cv_2_valid cv_3_valid\nmae                      0.112069  0.003868   0.110514   0.118646   0.111860\nmean_residual_deviance   0.050346  0.003496   0.050188   0.055389   0.051883\nmse                      0.050346  0.003496   0.050188   0.055389   0.051883\nnull_deviance          224.017940 12.613392 220.105120 244.018360 227.994700\nr2                       0.517080  0.016213   0.498813   0.511007   0.507770\nresidual_deviance      108.197270  8.415395 110.263910 119.086914 112.222010\nrmse                     0.224273  0.007750   0.224028   0.235349   0.227777\nrmsle                    0.157645  0.004187   0.157953   0.164196   0.157973\n                       cv_4_valid cv_5_valid\nmae                      0.108535   0.110791\nmean_residual_deviance   0.046653   0.047618\nmse                      0.046653   0.047618\nnull_deviance          215.392840 212.578670\nr2                       0.537650   0.530161\nresidual_deviance       99.557594  99.855950\nrmse                     0.215993   0.218217\nrmsle                    0.153275   0.154830\n```\n\n\n:::\n\n```{.r .cell-code}\npredictions_tbl <- automl_leader %>% \n  h2o.predict(newdata = as.h2o(test_tbl)) %>%\n  as.tibble() %>%\n  bind_cols(\n    test_tbl %>%\n      select(everything())\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\npredictions_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4,764 × 24\n   predict     sku national_inv lead_time in_transit_qty forecast_3_month\n     <dbl>   <dbl>        <dbl>     <dbl>          <dbl>            <dbl>\n 1  0.355  1115453           55         8              0              216\n 2  0.904  1116446            4         9              0               43\n 3  0.288  1117011            1         8              0                2\n 4  0.682  1120866            4        12              0                0\n 5  0.0670 1120868            7         8              0                0\n 6  0.928  1121942            0         2              0             1200\n 7  0.447  1122449            1         2              0                0\n 8  0.496  1122461            0         2              0                5\n 9  0.720  1124935            4         8              1               20\n10  0.661  1125285            2         2              0                0\n# ℹ 4,754 more rows\n# ℹ 18 more variables: forecast_6_month <dbl>, forecast_9_month <dbl>,\n#   sales_1_month <dbl>, sales_3_month <dbl>, sales_6_month <dbl>,\n#   sales_9_month <dbl>, min_bank <dbl>, potential_issue <chr>,\n#   pieces_past_due <dbl>, perf_6_month_avg <dbl>, perf_12_month_avg <dbl>,\n#   local_bo_qty <dbl>, deck_risk <chr>, oe_constraint <chr>, ppap_risk <chr>,\n#   stop_auto_buy <chr>, rev_stop <chr>, product_backorder <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(train_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      sku           national_inv        lead_time     in_transit_qty     \n Min.   :1111620   Min.   : -1440.0   Min.   : 0.00   Min.   :     0.00  \n 1st Qu.:1515706   1st Qu.:     3.0   1st Qu.: 4.00   1st Qu.:     0.00  \n Median :1923738   Median :    12.0   Median : 8.00   Median :     0.00  \n Mean   :2060290   Mean   :   338.5   Mean   : 7.72   Mean   :    54.93  \n 3rd Qu.:2826658   3rd Qu.:    66.0   3rd Qu.: 8.00   3rd Qu.:     0.00  \n Max.   :3284775   Max.   :346702.0   Max.   :52.00   Max.   :170920.00  \n                                      NA's   :803                        \n forecast_3_month   forecast_6_month   forecast_9_month    sales_1_month      \n Min.   :     0.0   Min.   :     0.0   Min.   :      0.0   Min.   :     0.00  \n 1st Qu.:     0.0   1st Qu.:     0.0   1st Qu.:      0.0   1st Qu.:     0.00  \n Median :     0.0   Median :     0.0   Median :      0.0   Median :     0.00  \n Mean   :   203.7   Mean   :   384.9   Mean   :    556.3   Mean   :    63.18  \n 3rd Qu.:     9.0   3rd Qu.:    20.0   3rd Qu.:     30.0   3rd Qu.:     5.00  \n Max.   :479808.0   Max.   :967776.0   Max.   :1418208.0   Max.   :186451.00  \n                                                                              \n sales_3_month    sales_6_month       sales_9_month          min_bank       \n Min.   :     0   Min.   :      0.0   Min.   :      0.0   Min.   :    0.00  \n 1st Qu.:     0   1st Qu.:      0.0   1st Qu.:      0.0   1st Qu.:    0.00  \n Median :     2   Median :      3.0   Median :      5.0   Median :    0.00  \n Mean   :   191   Mean   :    379.5   Mean   :    572.1   Mean   :   52.68  \n 3rd Qu.:    16   3rd Qu.:     32.0   3rd Qu.:     48.0   3rd Qu.:    3.00  \n Max.   :550609   Max.   :1136154.0   Max.   :1759152.0   Max.   :85584.00  \n                                                                            \n potential_issue    pieces_past_due     perf_6_month_avg  perf_12_month_avg\n Length:14289       Min.   :    0.000   Min.   :-99.000   Min.   :-99.00   \n Class :character   1st Qu.:    0.000   1st Qu.:  0.630   1st Qu.:  0.66   \n Mode  :character   Median :    0.000   Median :  0.820   Median :  0.80   \n                    Mean   :    2.741   Mean   : -6.381   Mean   : -5.96   \n                    3rd Qu.:    0.000   3rd Qu.:  0.970   3rd Qu.:  0.95   \n                    Max.   :13824.000   Max.   :  1.000   Max.   :  1.00   \n                                                                           \n  local_bo_qty        deck_risk         oe_constraint       ppap_risk        \n Min.   :   0.0000   Length:14289       Length:14289       Length:14289      \n 1st Qu.:   0.0000   Class :character   Class :character   Class :character  \n Median :   0.0000   Mode  :character   Mode  :character   Mode  :character  \n Mean   :   0.9949                                                           \n 3rd Qu.:   0.0000                                                           \n Max.   :1440.0000                                                           \n                                                                             \n stop_auto_buy        rev_stop         product_backorder\n Length:14289       Length:14289       Min.   :0.0000   \n Class :character   Class :character   1st Qu.:0.0000   \n Mode  :character   Mode  :character   Median :0.0000   \n                                       Mean   :0.1171   \n                                       3rd Qu.:0.0000   \n                                       Max.   :1.0000   \n                                                        \n```\n\n\n:::\n\n```{.r .cell-code}\n## Original plot_features()\n\n# explanation %>% \n#   as.tibble()\n#   \n# case_1 <- explanation %>%\n#     filter(case == 1)\n# \n# case_1 %>%\n#     plot_features()\n# You will need at least the layers geom_col() and coord_flip().\nexplainer <- train_tbl %>%\n  select(-product_backorder) %>%\n  lime(\n    model           = automl_leader,\n    bin_continuous  = TRUE,\n    n_bins          = 4,\n    quantile_bins   = TRUE\n  )\nexplainer\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$model\nModel Details:\n==============\n\nH2ORegressionModel: stackedensemble\nModel ID:  StackedEnsemble_AllModels_3_AutoML_1_20240622_142532 \nModel Summary for Stacked Ensemble: \n                                         key            value\n1                          Stacking strategy cross_validation\n2       Number of base models (used / total)            19/50\n3           # GBM base models (used / total)            17/42\n4           # DRF base models (used / total)              2/2\n5  # DeepLearning base models (used / total)              0/5\n6           # GLM base models (used / total)              0/1\n7                      Metalearner algorithm              GLM\n8         Metalearner fold assignment scheme           Random\n9                         Metalearner nfolds                5\n10                   Metalearner fold_column               NA\n11        Custom metalearner hyperparameters             None\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on training data. **\n\nMSE:  0.01822598\nRMSE:  0.1350036\nMAE:  0.06575185\nRMSLE:  0.09474208\nMean Residual Deviance :  0.01822598\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on validation data. **\n\nMSE:  0.05120148\nRMSE:  0.2262774\nMAE:  0.1102032\nRMSLE:  0.1590233\nMean Residual Deviance :  0.05120148\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  0.05040252\nRMSE:  0.2245051\nMAE:  0.1120714\nRMSLE:  0.1578221\nMean Residual Deviance :  0.05040252\n\n\nCross-Validation Metrics Summary: \n                             mean        sd cv_1_valid cv_2_valid cv_3_valid\nmae                      0.112069  0.003868   0.110514   0.118646   0.111860\nmean_residual_deviance   0.050346  0.003496   0.050188   0.055389   0.051883\nmse                      0.050346  0.003496   0.050188   0.055389   0.051883\nnull_deviance          224.017940 12.613392 220.105120 244.018360 227.994700\nr2                       0.517080  0.016213   0.498813   0.511007   0.507770\nresidual_deviance      108.197270  8.415395 110.263910 119.086914 112.222010\nrmse                     0.224273  0.007750   0.224028   0.235349   0.227777\nrmsle                    0.157645  0.004187   0.157953   0.164196   0.157973\n                       cv_4_valid cv_5_valid\nmae                      0.108535   0.110791\nmean_residual_deviance   0.046653   0.047618\nmse                      0.046653   0.047618\nnull_deviance          215.392840 212.578670\nr2                       0.537650   0.530161\nresidual_deviance       99.557594  99.855950\nrmse                     0.215993   0.218217\nrmsle                    0.153275   0.154830\n\n$preprocess\nfunction (x) \nx\n<bytecode: 0x000002a90c88e5f8>\n<environment: 0x000002a90c888ac8>\n\n$bin_continuous\n[1] TRUE\n\n$n_bins\n[1] 4\n\n$quantile_bins\n[1] TRUE\n\n$use_density\n[1] TRUE\n\n$feature_type\n              sku      national_inv         lead_time    in_transit_qty \n        \"numeric\"         \"numeric\"         \"numeric\"         \"numeric\" \n forecast_3_month  forecast_6_month  forecast_9_month     sales_1_month \n        \"numeric\"         \"numeric\"         \"numeric\"         \"numeric\" \n    sales_3_month     sales_6_month     sales_9_month          min_bank \n        \"numeric\"         \"numeric\"         \"numeric\"         \"numeric\" \n  potential_issue   pieces_past_due  perf_6_month_avg perf_12_month_avg \n      \"character\"         \"numeric\"         \"numeric\"         \"numeric\" \n     local_bo_qty         deck_risk     oe_constraint         ppap_risk \n        \"numeric\"       \"character\"       \"character\"       \"character\" \n    stop_auto_buy          rev_stop \n      \"character\"       \"character\" \n\n$bin_cuts\n$bin_cuts$sku\n     0%     25%     50%     75%    100% \n1111620 1515706 1923738 2826658 3284775 \n\n$bin_cuts$national_inv\n    0%    25%    50%    75%   100% \n -1440      3     12     66 346702 \n\n$bin_cuts$lead_time\n  0%  25%  50% 100% \n   0    4    8   52 \n\n$bin_cuts$in_transit_qty\n[1]      0  42730  85460 128190 170920\n\n$bin_cuts$forecast_3_month\n    0%    75%   100% \n     0      9 479808 \n\n$bin_cuts$forecast_6_month\n    0%    75%   100% \n     0     20 967776 \n\n$bin_cuts$forecast_9_month\n     0%     75%    100% \n      0      30 1418208 \n\n$bin_cuts$sales_1_month\n    0%    75%   100% \n     0      5 186451 \n\n$bin_cuts$sales_3_month\n    0%    50%    75%   100% \n     0      2     16 550609 \n\n$bin_cuts$sales_6_month\n     0%     50%     75%    100% \n      0       3      32 1136154 \n\n$bin_cuts$sales_9_month\n     0%     50%     75%    100% \n      0       5      48 1759152 \n\n$bin_cuts$min_bank\n   0%   75%  100% \n    0     3 85584 \n\n$bin_cuts$potential_issue\nNULL\n\n$bin_cuts$pieces_past_due\n[1]     0  3456  6912 10368 13824\n\n$bin_cuts$perf_6_month_avg\n    0%    25%    50%    75%   100% \n-99.00   0.63   0.82   0.97   1.00 \n\n$bin_cuts$perf_12_month_avg\n    0%    25%    50%    75%   100% \n-99.00   0.66   0.80   0.95   1.00 \n\n$bin_cuts$local_bo_qty\n[1]    0  360  720 1080 1440\n\n$bin_cuts$deck_risk\nNULL\n\n$bin_cuts$oe_constraint\nNULL\n\n$bin_cuts$ppap_risk\nNULL\n\n$bin_cuts$stop_auto_buy\nNULL\n\n$bin_cuts$rev_stop\nNULL\n\n\n$feature_distribution\n$feature_distribution$sku\n\n        1         2         3         4 \n0.2500525 0.2499825 0.2499825 0.2499825 \n\n$feature_distribution$national_inv\n\n        1         2         3         4 \n0.2716075 0.2427042 0.2375254 0.2481629 \n\n$feature_distribution$lead_time\n\n        1         2         3 \n0.2998810 0.4147946 0.2291273 \n\n$feature_distribution$in_transit_qty\n\n           1            2            4 \n0.9997900483 0.0001399678 0.0000699839 \n\n$feature_distribution$forecast_3_month\n\n        1         2 \n0.7507173 0.2492827 \n\n$feature_distribution$forecast_6_month\n\n        1         2 \n0.7550563 0.2449437 \n\n$feature_distribution$forecast_9_month\n\n        1         2 \n0.7536567 0.2463433 \n\n$feature_distribution$sales_1_month\n\n        1         2 \n0.7593953 0.2406047 \n\n$feature_distribution$sales_3_month\n\n        1         2         3 \n0.5490937 0.2016936 0.2492127 \n\n$feature_distribution$sales_6_month\n\n        1         2         3 \n0.5048639 0.2451536 0.2499825 \n\n$feature_distribution$sales_9_month\n\n        1         2         3 \n0.5104626 0.2413045 0.2482329 \n\n$feature_distribution$min_bank\n\n        1         2 \n0.7530268 0.2469732 \n\n$feature_distribution$potential_issue\n\n         No         Yes \n0.998600322 0.001399678 \n\n$feature_distribution$pieces_past_due\n\n          1           2           4 \n9.99860e-01 6.99839e-05 6.99839e-05 \n\n$feature_distribution$perf_6_month_avg\n\n        1         2         3         4 \n0.2578907 0.2564210 0.2702079 0.2154804 \n\n$feature_distribution$perf_12_month_avg\n\n        1         2         3         4 \n0.2804955 0.2236686 0.2604801 0.2353559 \n\n$feature_distribution$local_bo_qty\n\n           1            2            3            4 \n0.9993701449 0.0002799356 0.0000699839 0.0002799356 \n\n$feature_distribution$deck_risk\n\n       No       Yes \n0.7787809 0.2212191 \n\n$feature_distribution$oe_constraint\n\n          No          Yes \n0.9997900483 0.0002099517 \n\n$feature_distribution$ppap_risk\n\n       No       Yes \n0.8775982 0.1224018 \n\n$feature_distribution$stop_auto_buy\n\n        No        Yes \n0.03492197 0.96507803 \n\n$feature_distribution$rev_stop\n\n          No          Yes \n0.9994401288 0.0005598712 \n\n\nattr(,\"class\")\n[1] \"data_frame_explainer\" \"explainer\"            \"list\"                \n```\n\n\n:::\n\n```{.r .cell-code}\nexplanation <- test_tbl %>%\n  slice(1) %>%\n  select(-product_backorder) %>%\n  lime::explain(\n    \n    # Pass our explainer object\n    explainer = explainer,\n    # Because it is a binary classification model: 1\n    n_labels   = 1,\n    # number of features to be returned\n    n_features = 8,\n    # number of localized linear models\n    n_permutations = 5000,\n    # Let's start with 1\n    kernel_width   = 1\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nexplanation\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 × 11\n  model_type case  model_r2 model_intercept model_prediction feature         \n  <chr>      <chr>    <dbl>           <dbl>            <dbl> <chr>           \n1 regression 1        0.273           0.193            0.596 forecast_3_month\n2 regression 1        0.273           0.193            0.596 oe_constraint   \n3 regression 1        0.273           0.193            0.596 rev_stop        \n4 regression 1        0.273           0.193            0.596 potential_issue \n5 regression 1        0.273           0.193            0.596 sku             \n6 regression 1        0.273           0.193            0.596 perf_6_month_avg\n7 regression 1        0.273           0.193            0.596 local_bo_qty    \n8 regression 1        0.273           0.193            0.596 min_bank        \n# ℹ 5 more variables: feature_value <chr>, feature_weight <dbl>,\n#   feature_desc <chr>, data <list>, prediction <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\ng <- plot_features(explanation = explanation, ncol = 1, cases = 1)\ng\n```\n\n::: {.cell-output-display}\n![](05_lime_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n## Bonus Objectives:\n\nexplanation_multi <- test_tbl %>%\n  slice(1:20) %>%\n  select(-product_backorder) %>%\n  lime::explain(\n    explainer = explainer,\n    n_labels   = 1,\n    n_features = 8,\n    n_permutations = 5000,\n    kernel_width   = 0.5\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nexplanation_multi %>%\n  as.tibble()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 160 × 11\n   model_type case  model_r2 model_intercept model_prediction feature         \n   <chr>      <chr>    <dbl>           <dbl>            <dbl> <chr>           \n 1 regression 1        0.274          0.0786            0.594 forecast_3_month\n 2 regression 1        0.274          0.0786            0.594 rev_stop        \n 3 regression 1        0.274          0.0786            0.594 oe_constraint   \n 4 regression 1        0.274          0.0786            0.594 pieces_past_due \n 5 regression 1        0.274          0.0786            0.594 sku             \n 6 regression 1        0.274          0.0786            0.594 perf_6_month_avg\n 7 regression 1        0.274          0.0786            0.594 forecast_6_month\n 8 regression 1        0.274          0.0786            0.594 potential_issue \n 9 regression 2        0.302          0.186             0.635 forecast_3_month\n10 regression 2        0.302          0.186             0.635 in_transit_qty  \n# ℹ 150 more rows\n# ℹ 5 more variables: feature_value <chr>, feature_weight <dbl>,\n#   feature_desc <chr>, data <list>, prediction <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\nplot_explanations(explanation_multi)\n```\n\n::: {.cell-output-display}\n![](05_lime_files/figure-html/unnamed-chunk-1-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Part 2: Recreate plot_explanations():\n## Customized plot_features()\n\ntheme_lime <- function(...) {\n  theme_minimal() +\n    theme(\n      strip.text = element_text(face = 'bold', size = 9),\n      plot.margin = margin(15, 15, 15, 15),\n      legend.background = element_blank(),\n      legend.key = element_blank(),\n      panel.grid.major.y = element_blank(),\n      panel.grid.minor.y = element_blank(),\n      axis.ticks = element_blank(),\n      legend.position = 'bottom',\n      panel.spacing.y = unit(15, 'pt'),\n      strip.text.x = element_text(margin = margin(t = 2, b = 2), hjust = 0),\n      axis.title.y = element_text(margin = margin(r = 10)),\n      axis.title.x = element_text(margin = margin(t = 10)),\n      panel.background = element_rect(fill   = \"transparent\"),\n      panel.border     = element_rect(color = \"black\", fill = NA, size = 0.5),\n      panel.grid.major = element_line(color = \"grey\", size = 0.333),\n      ...\n    )\n}\n\nplot_explanations_customized <- function(explanation, ...) {\n  num_cases <- unique(suppressWarnings(as.numeric(explanation$case)))\n  if (!anyNA(num_cases)) {\n    explanation$case <- factor(explanation$case, levels = as.character(sort(num_cases)))\n  }\n  explanation$feature_desc <- factor(\n    explanation$feature_desc,\n    levels = rev(unique(explanation$feature_desc[order(explanation$feature, explanation$feature_value)]))\n  )\n  \n  \n  p <- ggplot(explanation, aes_(~case, ~feature_desc),show.legend=TRUE) +\n    geom_tile(aes_(fill = ~feature_weight)) +\n    scale_x_discrete('Case', expand = c(0, 0)) +\n    scale_y_discrete('Feature', expand = c(0, 0)) +\n    scale_fill_gradient2('Feature\\nweight', low = 'firebrick', mid = '#f7f7f7', high = 'steelblue') +\n    theme_lime() +\n    theme(panel.border = element_rect(fill = NA, colour = 'grey60', size = 1),\n          panel.grid = element_blank(),\n          legend.position = 'right',\n          axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))\n  if (is.null(explanation$label)) {\n    p\n  } else {\n    p + facet_wrap(~label, ...)\n  }\n}\n\n\n\nplot_explanations_customized(explanation = explanation, ncol = 1, cases = 1)\n```\n\n::: {.cell-output-display}\n![](05_lime_files/figure-html/unnamed-chunk-1-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_explanations_customized(explanation_multi)\n```\n\n::: {.cell-output-display}\n![](05_lime_files/figure-html/unnamed-chunk-1-4.png){width=672}\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}