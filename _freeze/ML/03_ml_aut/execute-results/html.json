{
  "hash": "ab1541e0972b52d07b111c6416f009a5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"03 Automated Machine Learning with H20\"\ndate: \"2024-06-22\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    df_print: paged\n    collapsed: false\n    number_sections: true\n    toc_depth: 3\n    #code_folding: hide\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Business case study Challenge 1\n\n# Libraries \nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(skimr)\nlibrary(GGally)\nlibrary(rsample)\n# Load Data data definitions\nemployee_attrition_tbl <- read_csv(\"C:/Users/risho/OneDrive/Desktop/internship_sparks/ss24-bdml-rishon1234/ML/data/Business Decisions with Machine Learning/datasets-1067-1925-WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 1470 Columns: 35\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (9): Attrition, BusinessTravel, Department, EducationField, Gender, Job...\ndbl (26): Age, DailyRate, DistanceFromHome, Education, EmployeeCount, Employ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\npath_data_definitions <- \"C:/Users/risho/OneDrive/Desktop/internship_sparks/ss24-bdml-rishon1234/ML/data/Business Decisions with Machine Learning/data_definitions.xlsx\"\ndefinitions_raw_tbl   <- read_excel(path_data_definitions, sheet = 1, col_names = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNew names:\n• `` -> `...1`\n• `` -> `...2`\n```\n\n\n:::\n\n```{.r .cell-code}\nemployee_attrition_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,470 × 35\n     Age Attrition BusinessTravel    DailyRate Department       DistanceFromHome\n   <dbl> <chr>     <chr>                 <dbl> <chr>                       <dbl>\n 1    41 Yes       Travel_Rarely          1102 Sales                           1\n 2    49 No        Travel_Frequently       279 Research & Deve…                8\n 3    37 Yes       Travel_Rarely          1373 Research & Deve…                2\n 4    33 No        Travel_Frequently      1392 Research & Deve…                3\n 5    27 No        Travel_Rarely           591 Research & Deve…                2\n 6    32 No        Travel_Frequently      1005 Research & Deve…                2\n 7    59 No        Travel_Rarely          1324 Research & Deve…                3\n 8    30 No        Travel_Rarely          1358 Research & Deve…               24\n 9    38 No        Travel_Frequently       216 Research & Deve…               23\n10    36 No        Travel_Rarely          1299 Research & Deve…               27\n# ℹ 1,460 more rows\n# ℹ 29 more variables: Education <dbl>, EducationField <chr>,\n#   EmployeeCount <dbl>, EmployeeNumber <dbl>, EnvironmentSatisfaction <dbl>,\n#   Gender <chr>, HourlyRate <dbl>, JobInvolvement <dbl>, JobLevel <dbl>,\n#   JobRole <chr>, JobSatisfaction <dbl>, MaritalStatus <chr>,\n#   MonthlyIncome <dbl>, MonthlyRate <dbl>, NumCompaniesWorked <dbl>,\n#   Over18 <chr>, OverTime <chr>, PercentSalaryHike <dbl>, …\n```\n\n\n:::\n\n```{.r .cell-code}\n# Business & Data Understanding: Department and Job Role\n# Data subset\ndept_job_role_tbl <- employee_attrition_tbl %>%\n  select(EmployeeNumber, Department, JobRole, PerformanceRating, Attrition)\ndept_job_role_tbl %>%\n  group_by(Attrition) %>%\n  summarize(n = n()) %>%\n  ungroup() %>%\n  mutate(pct = n / sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 3\n  Attrition     n   pct\n  <chr>     <int> <dbl>\n1 No         1233 0.839\n2 Yes         237 0.161\n```\n\n\n:::\n\n```{.r .cell-code}\n# Attrition by department\ndept_job_role_tbl %>%\n  # Block 1\n  group_by(Department, Attrition) %>%\n  summarize(n = n()) %>%\n  ungroup() %>%\n  # Block 2: Caution: It's easy to inadvertently miss grouping when creating counts & percents within groups\n  group_by(Department) %>%\n  mutate(pct = n / sum(n))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'Department'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n# Groups:   Department [3]\n  Department             Attrition     n   pct\n  <chr>                  <chr>     <int> <dbl>\n1 Human Resources        No           51 0.810\n2 Human Resources        Yes          12 0.190\n3 Research & Development No          828 0.862\n4 Research & Development Yes         133 0.138\n5 Sales                  No          354 0.794\n6 Sales                  Yes          92 0.206\n```\n\n\n:::\n\n```{.r .cell-code}\n# Attrition by job role\ndept_job_role_tbl %>%\n  # Block 1\n  group_by(Department, JobRole, Attrition) %>%\n  summarize(n = n()) %>%\n  ungroup() %>%\n  # Block 2\n  group_by(Department, JobRole) %>%\n  mutate(pct = n / sum(n)) %>%\n  ungroup() %>%\n  # Block 3\n  filter(Attrition %in% \"Yes\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'Department', 'JobRole'. You can override\nusing the `.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 5\n   Department             JobRole                   Attrition     n    pct\n   <chr>                  <chr>                     <chr>     <int>  <dbl>\n 1 Human Resources        Human Resources           Yes          12 0.231 \n 2 Research & Development Healthcare Representative Yes           9 0.0687\n 3 Research & Development Laboratory Technician     Yes          62 0.239 \n 4 Research & Development Manager                   Yes           3 0.0556\n 5 Research & Development Manufacturing Director    Yes          10 0.0690\n 6 Research & Development Research Director         Yes           2 0.025 \n 7 Research & Development Research Scientist        Yes          47 0.161 \n 8 Sales                  Manager                   Yes           2 0.0541\n 9 Sales                  Sales Executive           Yes          57 0.175 \n10 Sales                  Sales Representative      Yes          33 0.398 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Develop KPI\ndept_job_role_tbl %>%\n  # Block 1\n  group_by(Department, JobRole, Attrition) %>%\n  summarize(n = n()) %>%\n  ungroup() %>%\n  # Block 2\n  group_by(Department, JobRole) %>%\n  mutate(pct = n / sum(n)) %>%\n  ungroup() %>%\n  # Block 3\n  filter(Attrition %in% \"Yes\") %>%\n  arrange(desc(pct)) %>%\n  mutate(\n    above_industry_avg = case_when(\n      pct > 0.088 ~ \"Yes\",\n      TRUE ~ \"No\"\n    )\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'Department', 'JobRole'. You can override\nusing the `.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 6\n   Department             JobRole      Attrition     n    pct above_industry_avg\n   <chr>                  <chr>        <chr>     <int>  <dbl> <chr>             \n 1 Sales                  Sales Repre… Yes          33 0.398  Yes               \n 2 Research & Development Laboratory … Yes          62 0.239  Yes               \n 3 Human Resources        Human Resou… Yes          12 0.231  Yes               \n 4 Sales                  Sales Execu… Yes          57 0.175  Yes               \n 5 Research & Development Research Sc… Yes          47 0.161  Yes               \n 6 Research & Development Manufacturi… Yes          10 0.0690 No                \n 7 Research & Development Healthcare … Yes           9 0.0687 No                \n 8 Research & Development Manager      Yes           3 0.0556 No                \n 9 Sales                  Manager      Yes           2 0.0541 No                \n10 Research & Development Research Di… Yes           2 0.025  No                \n```\n\n\n:::\n\n```{.r .cell-code}\n# Function to calculate attrition cost\ncalculate_attrition_cost <- function(\n    # Employee\n  n                    = 1,\n  salary               = 80000,\n  # Direct Costs\n  separation_cost      = 500,\n  vacancy_cost         = 10000,\n  acquisition_cost     = 4900,\n  placement_cost       = 3500,\n  # Productivity Costs\n  net_revenue_per_employee = 250000,\n  workdays_per_year        = 240,\n  workdays_position_open   = 40,\n  workdays_onboarding      = 60,\n  onboarding_efficiency    = 0.50\n) {\n  # Direct Costs\n  direct_cost <- sum(separation_cost, vacancy_cost, acquisition_cost, placement_cost)\n  # Lost Productivity Costs\n  productivity_cost <- net_revenue_per_employee / workdays_per_year *\n    (workdays_position_open + workdays_onboarding * onboarding_efficiency)\n  # Savings of Salary & Benefits (Cost Reduction)\n  salary_benefit_reduction <- salary / workdays_per_year * workdays_position_open\n  # Estimated Turnover Per Employee\n  cost_per_employee <- direct_cost + productivity_cost - salary_benefit_reduction\n  # Total Cost of Employee Turnover\n  total_cost <- n * cost_per_employee\n  return(total_cost)\n}\ncalculate_attrition_cost()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 78483.33\n```\n\n\n:::\n\n```{.r .cell-code}\ncalculate_attrition_cost(200)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 15696667\n```\n\n\n:::\n\n```{.r .cell-code}\n# Use this\n# Function to convert counts to percentages. \ncount_to_pct <- function(data, ..., col = n) {\n  # capture the dots\n  grouping_vars_expr <- quos(...)\n  col_expr <- enquo(col)\n  ret <- data %>%\n    group_by(!!! grouping_vars_expr) %>%\n    mutate(pct = (!! col_expr) / sum(!! col_expr)) %>%\n    ungroup()\n  return(ret)\n}\n# This is way shorter and more flexibel\ndept_job_role_tbl %>%\n  count(JobRole, Attrition) %>%\n  count_to_pct(JobRole)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 18 × 4\n   JobRole                   Attrition     n    pct\n   <chr>                     <chr>     <int>  <dbl>\n 1 Healthcare Representative No          122 0.931 \n 2 Healthcare Representative Yes           9 0.0687\n 3 Human Resources           No           40 0.769 \n 4 Human Resources           Yes          12 0.231 \n 5 Laboratory Technician     No          197 0.761 \n 6 Laboratory Technician     Yes          62 0.239 \n 7 Manager                   No           97 0.951 \n 8 Manager                   Yes           5 0.0490\n 9 Manufacturing Director    No          135 0.931 \n10 Manufacturing Director    Yes          10 0.0690\n11 Research Director         No           78 0.975 \n12 Research Director         Yes           2 0.025 \n13 Research Scientist        No          245 0.839 \n14 Research Scientist        Yes          47 0.161 \n15 Sales Executive           No          269 0.825 \n16 Sales Executive           Yes          57 0.175 \n17 Sales Representative      No           50 0.602 \n18 Sales Representative      Yes          33 0.398 \n```\n\n\n:::\n\n```{.r .cell-code}\ndept_job_role_tbl %>%\n  count(Department, JobRole, Attrition) %>%\n  count_to_pct(Department, JobRole)  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 21 × 5\n   Department             JobRole                   Attrition     n    pct\n   <chr>                  <chr>                     <chr>     <int>  <dbl>\n 1 Human Resources        Human Resources           No           40 0.769 \n 2 Human Resources        Human Resources           Yes          12 0.231 \n 3 Human Resources        Manager                   No           11 1     \n 4 Research & Development Healthcare Representative No          122 0.931 \n 5 Research & Development Healthcare Representative Yes           9 0.0687\n 6 Research & Development Laboratory Technician     No          197 0.761 \n 7 Research & Development Laboratory Technician     Yes          62 0.239 \n 8 Research & Development Manager                   No           51 0.944 \n 9 Research & Development Manager                   Yes           3 0.0556\n10 Research & Development Manufacturing Director    No          135 0.931 \n# ℹ 11 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nassess_attrition <- function(data, attrition_col, attrition_value, baseline_pct) {\n  attrition_col_expr <- enquo(attrition_col)\n  data %>%\n    \n    # Use parenthesis () to give tidy eval evaluation priority\n    filter((!! attrition_col_expr) %in% attrition_value) %>%\n    arrange(desc(pct)) %>%\n    mutate(\n      # Function inputs in numeric format (e.g. baseline_pct = 0.088 don't require tidy eval)\n      above_industry_avg = case_when(\n        pct > baseline_pct ~ \"Yes\",\n        TRUE ~ \"No\"\n      )\n    )\n}\ndept_job_role_tbl %>%\n  count(Department, JobRole, Attrition) %>%\n  count_to_pct(Department, JobRole) %>%\n  assess_attrition(Attrition, attrition_value = \"Yes\", baseline_pct = 0.088) %>%\n  mutate(\n    cost_of_attrition = calculate_attrition_cost(n = n, salary = 80000)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 7\n   Department             JobRole      Attrition     n    pct above_industry_avg\n   <chr>                  <chr>        <chr>     <int>  <dbl> <chr>             \n 1 Sales                  Sales Repre… Yes          33 0.398  Yes               \n 2 Research & Development Laboratory … Yes          62 0.239  Yes               \n 3 Human Resources        Human Resou… Yes          12 0.231  Yes               \n 4 Sales                  Sales Execu… Yes          57 0.175  Yes               \n 5 Research & Development Research Sc… Yes          47 0.161  Yes               \n 6 Research & Development Manufacturi… Yes          10 0.0690 No                \n 7 Research & Development Healthcare … Yes           9 0.0687 No                \n 8 Research & Development Manager      Yes           3 0.0556 No                \n 9 Sales                  Manager      Yes           2 0.0541 No                \n10 Research & Development Research Di… Yes           2 0.025  No                \n# ℹ 1 more variable: cost_of_attrition <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\ndept_job_role_tbl %>%\n  group_by(Department, JobRole, Attrition) %>%\n  summarize(n = n()) %>%\n  ungroup() %>%\n  group_by(Department, JobRole) %>%\n  mutate(pct = n / sum(n)) %>%\n  ungroup() %>%\n  filter(Attrition %in% \"Yes\") %>%\n  arrange(desc(pct)) %>%\n  mutate(\n    above_industry_avg = case_when(\n      pct > 0.088 ~ \"Yes\",\n      TRUE ~ \"No\"\n    )\n  ) %>%\n  mutate(\n    cost_of_attrition = calculate_attrition_cost(n = n, salary = 80000)\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'Department', 'JobRole'. You can override\nusing the `.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 7\n   Department             JobRole      Attrition     n    pct above_industry_avg\n   <chr>                  <chr>        <chr>     <int>  <dbl> <chr>             \n 1 Sales                  Sales Repre… Yes          33 0.398  Yes               \n 2 Research & Development Laboratory … Yes          62 0.239  Yes               \n 3 Human Resources        Human Resou… Yes          12 0.231  Yes               \n 4 Sales                  Sales Execu… Yes          57 0.175  Yes               \n 5 Research & Development Research Sc… Yes          47 0.161  Yes               \n 6 Research & Development Manufacturi… Yes          10 0.0690 No                \n 7 Research & Development Healthcare … Yes           9 0.0687 No                \n 8 Research & Development Manager      Yes           3 0.0556 No                \n 9 Sales                  Manager      Yes           2 0.0541 No                \n10 Research & Development Research Di… Yes           2 0.025  No                \n# ℹ 1 more variable: cost_of_attrition <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\ndept_job_role_tbl %>%\n  count(Department, JobRole, Attrition) %>%\n  count_to_pct(Department, JobRole) %>%\n  assess_attrition(Attrition, attrition_value = \"Yes\", baseline_pct = 0.088) %>%\n  mutate(\n    cost_of_attrition = calculate_attrition_cost(n = n, salary = 80000)\n  ) %>%\n  # Data Manipulation\n  mutate(name = str_c(Department, JobRole, sep = \": \") %>% as_factor()) %>%\n  # Check levels\n  # pull(name) %>%\n  # levels()\n  mutate(name      = fct_reorder(name, cost_of_attrition)) %>%\n  mutate(cost_text = str_c(\"$\", format(cost_of_attrition / 1e6, digits = 2),\n                           \"M\", sep = \"\")) %>%\n  #Plotting\n  ggplot(aes(cost_of_attrition, y = name)) +\n  geom_segment(aes(xend = 0, yend = name),    color = \"#2dc6d6\") +\n  geom_point(  aes(size = cost_of_attrition), color = \"#2dc6d6\") +\n  scale_x_continuous(labels = scales::dollar) +\n  geom_label(aes(label = cost_text, size = cost_of_attrition),\n             hjust = \"inward\", color = \"#2dc6d6\") +\n  scale_size(range = c(3, 5)) +\n  labs(title = \"Estimated cost of Attrition: By Dept and Job Role\",\n       y = \"\",\n       x = \"Cost of attrition\") +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](03_ml_aut_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Function to plot attrition\nplot_attrition <- function(data, \n                           ..., \n                           .value,\n                           fct_reorder = TRUE,\n                           fct_rev     = FALSE,\n                           include_lbl = TRUE,\n                           color       = \"#2dc6d6\",\n                           units       = c(\"0\", \"K\", \"M\")) {\n  ### Inputs\n  group_vars_expr   <- quos(...)\n  \n  # If the user does not supply anything, \n  # this takes the first column of the supplied data\n  if (length(group_vars_expr) == 0) {\n    group_vars_expr <- quos(rlang::sym(colnames(data)[[1]]))\n  }\n  value_expr <- enquo(.value)\n  units_val  <- switch(units[[1]],\n                       \"M\" = 1e6,\n                       \"K\" = 1e3,\n                       \"0\" = 1)\n  if (units[[1]] == \"0\") units <- \"\"\n  # Data Manipulation\n  # This is a so called Function Factory (a function that produces a function)\n  usd <- scales::dollar_format(prefix = \"$\", largest_with_cents = 1e3)\n  # Create the axis labels and values for the plot\n  data_manipulated <- data %>%\n    mutate(name = str_c(!!! group_vars_expr, sep = \": \") %>% as_factor()) %>%\n    mutate(value_text = str_c(usd(!! value_expr / units_val),\n                              units[[1]], sep = \"\"))\n  \n  # Order the labels on the y-axis according to the input\n  if (fct_reorder) {\n    data_manipulated <- data_manipulated %>%\n      mutate(name = forcats::fct_reorder(name, !! value_expr)) %>%\n      arrange(name)\n  }\n  if (fct_rev) {\n    data_manipulated <- data_manipulated %>%\n      mutate(name = forcats::fct_rev(name)) %>%\n      arrange(name)\n  }\n  # Visualization\n  g <- data_manipulated %>%\n    # \"name\" is a column name generated by our function internally as part of the data manipulation task\n    ggplot(aes(x = (!! value_expr), y = name)) +\n    geom_segment(aes(xend = 0, yend = name), color = color) +\n    geom_point(aes(size = !! value_expr), color = color) +\n    scale_x_continuous(labels = scales::dollar) +\n    scale_size(range = c(3, 5)) +\n    theme(legend.position = \"none\")\n  # Plot labels if TRUE\n  if (include_lbl) {\n    g <- g +\n      geom_label(aes(label = value_text, size = !! value_expr),\n                 hjust = \"inward\", color = color)\n  }\n  return(g)\n}\ndept_job_role_tbl %>%\n  # Select columnns\n  count(Department, JobRole, Attrition) %>%\n  count_to_pct(Department, JobRole) %>%\n  \n  assess_attrition(Attrition, attrition_value = \"Yes\", baseline_pct = 0.088) %>%\n  mutate(\n    cost_of_attrition = calculate_attrition_cost(n = n, salary = 80000)\n  ) %>%\n  # Select columnns\n  plot_attrition(Department, JobRole, .value = cost_of_attrition,\n                 units = \"M\") +\n  labs(\n    title = \"Estimated Cost of Attrition by Job Role\",\n    x = \"Cost of Attrition\",\n    subtitle = \"Looks like Sales Executive and Labaratory Technician are the biggest drivers of cost\"\n  )\n```\n\n::: {.cell-output-display}\n![](03_ml_aut_files/figure-html/unnamed-chunk-1-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Step 1: Data Summarization -----\nskim(employee_attrition_tbl)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |                       |\n|:------------------------|:----------------------|\n|Name                     |employee_attrition_tbl |\n|Number of rows           |1470                   |\n|Number of columns        |35                     |\n|_______________________  |                       |\n|Column type frequency:   |                       |\n|character                |9                      |\n|numeric                  |26                     |\n|________________________ |                       |\n|Group variables          |None                   |\n\n\n**Variable type: character**\n\n|skim_variable  | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:--------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|Attrition      |         0|             1|   2|   3|     0|        2|          0|\n|BusinessTravel |         0|             1|  10|  17|     0|        3|          0|\n|Department     |         0|             1|   5|  22|     0|        3|          0|\n|EducationField |         0|             1|   5|  16|     0|        6|          0|\n|Gender         |         0|             1|   4|   6|     0|        2|          0|\n|JobRole        |         0|             1|   7|  25|     0|        9|          0|\n|MaritalStatus  |         0|             1|   6|   8|     0|        3|          0|\n|Over18         |         0|             1|   1|   1|     0|        1|          0|\n|OverTime       |         0|             1|   2|   3|     0|        2|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable            | n_missing| complete_rate|     mean|      sd|   p0|     p25|     p50|      p75|  p100|hist  |\n|:------------------------|---------:|-------------:|--------:|-------:|----:|-------:|-------:|--------:|-----:|:-----|\n|Age                      |         0|             1|    36.92|    9.14|   18|   30.00|    36.0|    43.00|    60|▂▇▇▃▂ |\n|DailyRate                |         0|             1|   802.49|  403.51|  102|  465.00|   802.0|  1157.00|  1499|▇▇▇▇▇ |\n|DistanceFromHome         |         0|             1|     9.19|    8.11|    1|    2.00|     7.0|    14.00|    29|▇▅▂▂▂ |\n|Education                |         0|             1|     2.91|    1.02|    1|    2.00|     3.0|     4.00|     5|▂▃▇▆▁ |\n|EmployeeCount            |         0|             1|     1.00|    0.00|    1|    1.00|     1.0|     1.00|     1|▁▁▇▁▁ |\n|EmployeeNumber           |         0|             1|  1024.87|  602.02|    1|  491.25|  1020.5|  1555.75|  2068|▇▇▇▇▇ |\n|EnvironmentSatisfaction  |         0|             1|     2.72|    1.09|    1|    2.00|     3.0|     4.00|     4|▅▅▁▇▇ |\n|HourlyRate               |         0|             1|    65.89|   20.33|   30|   48.00|    66.0|    83.75|   100|▇▇▇▇▇ |\n|JobInvolvement           |         0|             1|     2.73|    0.71|    1|    2.00|     3.0|     3.00|     4|▁▃▁▇▁ |\n|JobLevel                 |         0|             1|     2.06|    1.11|    1|    1.00|     2.0|     3.00|     5|▇▇▃▂▁ |\n|JobSatisfaction          |         0|             1|     2.73|    1.10|    1|    2.00|     3.0|     4.00|     4|▅▅▁▇▇ |\n|MonthlyIncome            |         0|             1|  6502.93| 4707.96| 1009| 2911.00|  4919.0|  8379.00| 19999|▇▅▂▁▂ |\n|MonthlyRate              |         0|             1| 14313.10| 7117.79| 2094| 8047.00| 14235.5| 20461.50| 26999|▇▇▇▇▇ |\n|NumCompaniesWorked       |         0|             1|     2.69|    2.50|    0|    1.00|     2.0|     4.00|     9|▇▃▂▂▁ |\n|PercentSalaryHike        |         0|             1|    15.21|    3.66|   11|   12.00|    14.0|    18.00|    25|▇▅▃▂▁ |\n|PerformanceRating        |         0|             1|     3.15|    0.36|    3|    3.00|     3.0|     3.00|     4|▇▁▁▁▂ |\n|RelationshipSatisfaction |         0|             1|     2.71|    1.08|    1|    2.00|     3.0|     4.00|     4|▅▅▁▇▇ |\n|StandardHours            |         0|             1|    80.00|    0.00|   80|   80.00|    80.0|    80.00|    80|▁▁▇▁▁ |\n|StockOptionLevel         |         0|             1|     0.79|    0.85|    0|    0.00|     1.0|     1.00|     3|▇▇▁▂▁ |\n|TotalWorkingYears        |         0|             1|    11.28|    7.78|    0|    6.00|    10.0|    15.00|    40|▇▇▂▁▁ |\n|TrainingTimesLastYear    |         0|             1|     2.80|    1.29|    0|    2.00|     3.0|     3.00|     6|▂▇▇▂▃ |\n|WorkLifeBalance          |         0|             1|     2.76|    0.71|    1|    2.00|     3.0|     3.00|     4|▁▃▁▇▂ |\n|YearsAtCompany           |         0|             1|     7.01|    6.13|    0|    3.00|     5.0|     9.00|    40|▇▂▁▁▁ |\n|YearsInCurrentRole       |         0|             1|     4.23|    3.62|    0|    2.00|     3.0|     7.00|    18|▇▃▂▁▁ |\n|YearsSinceLastPromotion  |         0|             1|     2.19|    3.22|    0|    0.00|     1.0|     3.00|    15|▇▁▁▁▁ |\n|YearsWithCurrManager     |         0|             1|     4.12|    3.57|    0|    2.00|     3.0|     7.00|    17|▇▂▅▁▁ |\n\n\n:::\n\n```{.r .cell-code}\n# Character Data Type\nemployee_attrition_tbl %>%\n  select_if(is.character) %>%\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 1,470\nColumns: 9\n$ Attrition      <chr> \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n$ BusinessTravel <chr> \"Travel_Rarely\", \"Travel_Frequently\", \"Travel_Rarely\", …\n$ Department     <chr> \"Sales\", \"Research & Development\", \"Research & Developm…\n$ EducationField <chr> \"Life Sciences\", \"Life Sciences\", \"Other\", \"Life Scienc…\n$ Gender         <chr> \"Female\", \"Male\", \"Male\", \"Female\", \"Male\", \"Male\", \"Fe…\n$ JobRole        <chr> \"Sales Executive\", \"Research Scientist\", \"Laboratory Te…\n$ MaritalStatus  <chr> \"Single\", \"Married\", \"Single\", \"Married\", \"Married\", \"S…\n$ Over18         <chr> \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", …\n$ OverTime       <chr> \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No…\n```\n\n\n:::\n\n```{.r .cell-code}\n# Get \"levels\"\nemployee_attrition_tbl %>%\n  select_if(is.character) %>%\n  map(unique)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$Attrition\n[1] \"Yes\" \"No\" \n\n$BusinessTravel\n[1] \"Travel_Rarely\"     \"Travel_Frequently\" \"Non-Travel\"       \n\n$Department\n[1] \"Sales\"                  \"Research & Development\" \"Human Resources\"       \n\n$EducationField\n[1] \"Life Sciences\"    \"Other\"            \"Medical\"          \"Marketing\"       \n[5] \"Technical Degree\" \"Human Resources\" \n\n$Gender\n[1] \"Female\" \"Male\"  \n\n$JobRole\n[1] \"Sales Executive\"           \"Research Scientist\"       \n[3] \"Laboratory Technician\"     \"Manufacturing Director\"   \n[5] \"Healthcare Representative\" \"Manager\"                  \n[7] \"Sales Representative\"      \"Research Director\"        \n[9] \"Human Resources\"          \n\n$MaritalStatus\n[1] \"Single\"   \"Married\"  \"Divorced\"\n\n$Over18\n[1] \"Y\"\n\n$OverTime\n[1] \"Yes\" \"No\" \n```\n\n\n:::\n\n```{.r .cell-code}\n# Proportions    \nemployee_attrition_tbl %>%\n  select_if(is.character) %>%\n  map(~ table(.) %>% prop.table())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$Attrition\n.\n       No       Yes \n0.8387755 0.1612245 \n\n$BusinessTravel\n.\n       Non-Travel Travel_Frequently     Travel_Rarely \n        0.1020408         0.1884354         0.7095238 \n\n$Department\n.\n       Human Resources Research & Development                  Sales \n            0.04285714             0.65374150             0.30340136 \n\n$EducationField\n.\n Human Resources    Life Sciences        Marketing          Medical \n      0.01836735       0.41224490       0.10816327       0.31564626 \n           Other Technical Degree \n      0.05578231       0.08979592 \n\n$Gender\n.\nFemale   Male \n   0.4    0.6 \n\n$JobRole\n.\nHealthcare Representative           Human Resources     Laboratory Technician \n               0.08911565                0.03537415                0.17619048 \n                  Manager    Manufacturing Director         Research Director \n               0.06938776                0.09863946                0.05442177 \n       Research Scientist           Sales Executive      Sales Representative \n               0.19863946                0.22176871                0.05646259 \n\n$MaritalStatus\n.\n Divorced   Married    Single \n0.2224490 0.4578231 0.3197279 \n\n$Over18\n.\nY \n1 \n\n$OverTime\n.\n       No       Yes \n0.7170068 0.2829932 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Numeric Data\nemployee_attrition_tbl %>%\n  select_if(is.numeric) %>%\n  map(~ unique(.) %>% length())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$Age\n[1] 43\n\n$DailyRate\n[1] 886\n\n$DistanceFromHome\n[1] 29\n\n$Education\n[1] 5\n\n$EmployeeCount\n[1] 1\n\n$EmployeeNumber\n[1] 1470\n\n$EnvironmentSatisfaction\n[1] 4\n\n$HourlyRate\n[1] 71\n\n$JobInvolvement\n[1] 4\n\n$JobLevel\n[1] 5\n\n$JobSatisfaction\n[1] 4\n\n$MonthlyIncome\n[1] 1349\n\n$MonthlyRate\n[1] 1427\n\n$NumCompaniesWorked\n[1] 10\n\n$PercentSalaryHike\n[1] 15\n\n$PerformanceRating\n[1] 2\n\n$RelationshipSatisfaction\n[1] 4\n\n$StandardHours\n[1] 1\n\n$StockOptionLevel\n[1] 4\n\n$TotalWorkingYears\n[1] 40\n\n$TrainingTimesLastYear\n[1] 7\n\n$WorkLifeBalance\n[1] 4\n\n$YearsAtCompany\n[1] 37\n\n$YearsInCurrentRole\n[1] 19\n\n$YearsSinceLastPromotion\n[1] 16\n\n$YearsWithCurrManager\n[1] 18\n```\n\n\n:::\n\n```{.r .cell-code}\nemployee_attrition_tbl %>%\n  select_if(is.numeric) %>%\n  map_df(~ unique(.) %>% length()) %>%\n  # Select all columns\n  pivot_longer(everything()) %>%\n  arrange(value) %>%\n  filter(value <= 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 13 × 2\n   name                     value\n   <chr>                    <int>\n 1 EmployeeCount                1\n 2 StandardHours                1\n 3 PerformanceRating            2\n 4 EnvironmentSatisfaction      4\n 5 JobInvolvement               4\n 6 JobSatisfaction              4\n 7 RelationshipSatisfaction     4\n 8 StockOptionLevel             4\n 9 WorkLifeBalance              4\n10 Education                    5\n11 JobLevel                     5\n12 TrainingTimesLastYear        7\n13 NumCompaniesWorked          10\n```\n\n\n:::\n\n```{.r .cell-code}\n# Step 2: Data Visualization ----\nemployee_attrition_tbl %>%\n  select(Attrition, Age, Gender, MaritalStatus, NumCompaniesWorked, Over18, DistanceFromHome) %>%\n  ggpairs() \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](03_ml_aut_files/figure-html/unnamed-chunk-1-3.png){width=672}\n:::\n\n```{.r .cell-code}\nemployee_attrition_tbl %>%\n  select(Attrition, Age, Gender, MaritalStatus, NumCompaniesWorked, Over18, DistanceFromHome) %>%\n  ggpairs(aes(color = Attrition), lower = \"blank\", legend = 1,\n          diag  = list(continuous = wrap(\"densityDiag\", alpha = 0.5))) +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](03_ml_aut_files/figure-html/unnamed-chunk-1-4.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_ggpairs <- function(data, color = NULL, density_alpha = 0.5) {\n  \n  color_expr <- enquo(color)\n  \n  if (rlang::quo_is_null(color_expr)) {\n    \n    g <- data %>%\n      ggpairs(lower = \"blank\") \n    \n  } else {\n    \n    color_name <- quo_name(color_expr)\n    \n    g <- data %>%\n      ggpairs(mapping = aes_string(color = color_name), \n              lower = \"blank\", legend = 1,\n              diag = list(continuous = wrap(\"densityDiag\", \n                                            alpha = density_alpha))) +\n      theme(legend.position = \"bottom\",\n            text = element_text(size=8),\n            axis.text = element_text(size = 10),\n            axis.title = element_text(size = 10))\n  }\n  \n  return(g)\n  \n}\n\n\nemployee_attrition_tbl %>%\n  select(Attrition,  contains(\"Training\")) %>%\n  plot_ggpairs(Attrition)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](03_ml_aut_files/figure-html/unnamed-chunk-1-5.png){width=672}\n:::\n:::\n\n\n\n\n# Challenge 1\n\nUse your learning from descriptive features and plot_ggpairs() to further investigate the features. Run the functions above according to the features needed. Answer the following questions. Most of the time, you will only need the images from diagonal.\n\n***\n\n1. What can you deduce about the interaction between Monthly Income and Attrition?  <font color=red size=5>c</font>\n\na. Those that are leaving the company have a higher Monthly Income\nb. That those are staying have a lower Monthly Income\nc. Those that are leaving have a lower Monthly Income\nd. It's difficult to deduce anything based on the visualization\n\n***\n\n2. What can you deduce about the interaction between Percent Salary Hike and Attrition? <font color=red size=5>d</font>\n\na. Those that are leaving the company have a higher Percent Salary Hike\nb. Those that are staying have a lower Percent Salary Hike\nc. Those that are leaving have lower Percent Salary Hike\nd. It's difficult to deduce anything based on the visualization\n\n***\n\n3. What can you deduce about the interaction between Stock Option Level and Attrition? <font color=red size=5>b</font>\n\na. Those that are leaving the company have a higher stock option level\nb. Those that are staying have a higher stock option level\nc. It's difficult to deduce anything based on the visualization\n\n***\n\n4. What can you deduce about the interaction between Environment Satisfaction and Attrition? <font color=red size=5>a</font>\n\na. A higher proportion of those leaving have a low environment satisfaction level\nb. A higher proportion of those leaving have a high environment satisfaction level\nc. It's difficult to deduce anything based on the visualization\n\n***\n\n5. What can you deduce about the interaction between Work Life Balance and Attrition <font color=red size=5>b</font>\n\na. Those that are leaving have higher density of 2's and 3's\nb. Those that are staying have a higher density of 2's and 3's\nc. Those that are staying have a lower density of 2's and 3's\nd. It's difficult to deduce anything based on the visualization\n\n***\n\n6. What Can you deduce about the interaction between Job Involvement and Attrition? <font color=red size=5>a</font>\n\na. Those that are leaving have a lower density of 3's and 4's\nb. Those that are leaving have a lower density of 1's and 2's\nc. Those that are staying have a lower density of 2's and 3's\nd. It's difficult to deduce anything based on the visualization\n\n***\n\n7. What can you deduce about the interaction between Over Time and Attrition? <font color=red size=5>a</font>\n\na. The proportion of those leaving that are working Over Time are high compared to those that are not leaving\nb. The proportion of those staying that are working Over Time are high compared to those that are not staying\n\n***\n\n8. What can you deduce about the interaction between Training Times Last Year and Attrition <font color=red size=5>b</font>\n\na. People that leave tend to have more annual trainings\nb. People that leave tend to have less annual trainings\nc. It's difficult to deduce anything based on the visualization\n\n***\n\n9. What can you deduce about the interaction between Years At Company and Attrition <font color=red size=5>b</font>\n \na. People that leave tend to have more working years at the company\nb. People that leave tend to have less working years at the company\nc. It's difficult to deduce anything based on the visualization\n\n***\n\n10. What can you deduce about the interaction between Years Since Last Promotion and Attrition? <font color=red size=5>c</font>\n\na. Those that are leaving have more years since last promotion than those that are staying\nb. Those that are leaving have fewer years since last promotion than those that are staying\nc. It's difficult to deduce anything based on the visualization\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Challenge 2\n## Load the training & test dataset\nlibrary(tidyverse)\n# Modeling\nlibrary(parsnip)\n# Pre-processing & Sampling\nlibrary(recipes)\nlibrary(rsample)\n# Modeling Error Metrics\nlibrary(yardstick)\nlibrary(workflows)\nlibrary(tune)\n\nproduct_data <- read_csv(\"C:/Users/risho/OneDrive/Desktop/internship_sparks/ss24-bdml-rishon1234/ML/data/Business Decisions with Machine Learning/product_backorders.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 19053 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\ndbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nproduct_data2 <- product_data %>% \n  mutate(\n    product_backorder = went_on_backorder %>% str_to_lower() %>% str_detect(\"yes\") %>% as.numeric()\n  ) %>% \n  select(-c(went_on_backorder))\nglimpse(product_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 19,053\nColumns: 23\n$ sku               <dbl> 1113121, 1113268, 1113874, 1114222, 1114823, 1115453…\n$ national_inv      <dbl> 0, 0, 20, 0, 0, 55, -34, 4, 2, -7, 1, 2, 0, 0, 0, 0,…\n$ lead_time         <dbl> 8, 8, 2, 8, 12, 8, 8, 9, 8, 8, 8, 8, 12, 2, 12, 4, 2…\n$ in_transit_qty    <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0…\n$ forecast_3_month  <dbl> 6, 2, 45, 9, 31, 216, 120, 43, 4, 56, 2, 5, 5, 54, 4…\n$ forecast_6_month  <dbl> 6, 3, 99, 14, 31, 360, 240, 67, 6, 96, 4, 9, 6, 72, …\n$ forecast_9_month  <dbl> 6, 4, 153, 21, 31, 492, 240, 115, 9, 112, 6, 13, 9, …\n$ sales_1_month     <dbl> 0, 1, 16, 5, 7, 30, 83, 5, 1, 13, 0, 1, 0, 0, 1, 0, …\n$ sales_3_month     <dbl> 4, 2, 42, 17, 15, 108, 122, 22, 5, 30, 2, 5, 4, 0, 3…\n$ sales_6_month     <dbl> 9, 3, 80, 36, 33, 275, 144, 40, 6, 56, 3, 8, 5, 0, 4…\n$ sales_9_month     <dbl> 12, 3, 111, 43, 47, 340, 165, 58, 9, 76, 4, 11, 6, 0…\n$ min_bank          <dbl> 0, 0, 10, 0, 2, 51, 33, 4, 2, 0, 0, 0, 3, 4, 0, 0, 0…\n$ potential_issue   <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ pieces_past_due   <dbl> 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ perf_6_month_avg  <dbl> 0.90, 0.96, 0.81, 0.96, 0.98, 0.00, 1.00, 0.69, 1.00…\n$ perf_12_month_avg <dbl> 0.89, 0.97, 0.88, 0.98, 0.98, 0.00, 0.97, 0.68, 0.95…\n$ local_bo_qty      <dbl> 0, 0, 0, 0, 0, 0, 34, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, …\n$ deck_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ oe_constraint     <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ ppap_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No…\n$ stop_auto_buy     <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n$ rev_stop          <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ went_on_backorder <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n```\n\n\n:::\n\n```{.r .cell-code}\nsplit_obj<- initial_split(product_data2, prop = 0.75)\ntrain_tbl<- training(split_obj)\ntest_tbl<- testing(split_obj)\n\n## Specifiy the response and predictor variables\nrecipe_obj <- recipe(product_backorder ~., data = train_tbl) %>% \n  step_zv(all_predictors()) %>% \n  step_dummy(all_nominal(),-all_outcomes()) %>%\n  prep()\n\nsummary(recipe_obj)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 23 × 4\n   variable         type      role      source  \n   <chr>            <list>    <chr>     <chr>   \n 1 sku              <chr [2]> predictor original\n 2 national_inv     <chr [2]> predictor original\n 3 lead_time        <chr [2]> predictor original\n 4 in_transit_qty   <chr [2]> predictor original\n 5 forecast_3_month <chr [2]> predictor original\n 6 forecast_6_month <chr [2]> predictor original\n 7 forecast_9_month <chr [2]> predictor original\n 8 sales_1_month    <chr [2]> predictor original\n 9 sales_3_month    <chr [2]> predictor original\n10 sales_6_month    <chr [2]> predictor original\n# ℹ 13 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nglimpse(bake(recipe_obj,new_data = NULL))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 14,289\nColumns: 23\n$ sku                 <dbl> 2174683, 1906789, 1756085, 1286355, 1254784, 19498…\n$ national_inv        <dbl> 21, 25, 701, 387, 17, 4, 592, 5, 8, 0, 478, 12, 37…\n$ lead_time           <dbl> 12, 8, 52, 8, 8, 4, 4, 4, 8, 3, 8, 8, 8, 8, 2, 2, …\n$ in_transit_qty      <dbl> 0, 0, 0, 0, 0, 0, 125, 0, 0, 0, 114, 0, 19, 32, 10…\n$ forecast_3_month    <dbl> 2, 0, 0, 250, 16, 0, 755, 0, 40, 11, 100, 0, 207, …\n$ forecast_6_month    <dbl> 2, 0, 0, 500, 46, 2, 1255, 0, 40, 19, 400, 7, 318,…\n$ forecast_9_month    <dbl> 2, 0, 0, 750, 66, 2, 1755, 0, 40, 27, 600, 14, 574…\n$ sales_1_month       <dbl> 1, 0, 30, 14, 6, 0, 232, 0, 0, 3, 91, 2, 75, 85, 4…\n$ sales_3_month       <dbl> 6, 4, 66, 238, 20, 1, 778, 0, 5, 12, 304, 7, 255, …\n$ sales_6_month       <dbl> 9, 7, 156, 409, 42, 1, 1301, 2, 14, 17, 671, 18, 4…\n$ sales_9_month       <dbl> 19, 8, 206, 719, 71, 3, 1900, 2, 20, 27, 1061, 25,…\n$ min_bank            <dbl> 8, 3, 0, 42, 6, 0, 263, 0, 2, 0, 196, 2, 54, 83, 5…\n$ pieces_past_due     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ perf_6_month_avg    <dbl> 0.77, 0.98, 0.00, 0.90, 0.99, 0.73, 0.87, 0.73, 0.…\n$ perf_12_month_avg   <dbl> 0.75, 0.93, 0.00, 0.92, 0.99, 0.78, 0.92, 0.78, 0.…\n$ local_bo_qty        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ product_backorder   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,…\n$ potential_issue_Yes <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ deck_risk_Yes       <dbl> 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,…\n$ oe_constraint_Yes   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ ppap_risk_Yes       <dbl> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,…\n$ stop_auto_buy_Yes   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ rev_stop_Yes        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(h2o)\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nH2O is not running yet, starting it now...\n\nNote:  In case of errors look at the following log files:\n    C:\\Users\\risho\\AppData\\Local\\Temp\\Rtmp6b0GFl\\file8ad871fc1921/h2o_risho_started_from_r.out\n    C:\\Users\\risho\\AppData\\Local\\Temp\\Rtmp6b0GFl\\file8ad831793d0d/h2o_risho_started_from_r.err\n\n\nStarting H2O JVM and connecting:  Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         3 seconds 75 milliseconds \n    H2O cluster timezone:       Europe/Berlin \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.44.0.3 \n    H2O cluster version age:    6 months and 3 days \n    H2O cluster name:           H2O_started_from_R_risho_ejs496 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   1.91 GB \n    H2O cluster total cores:    12 \n    H2O cluster allowed cores:  12 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.4.0 (2024-04-24 ucrt) \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in h2o.clusterInfo(): \nYour H2O cluster version is (6 months and 3 days) old. There may be a newer version available.\nPlease download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n```\n\n\n:::\n\n```{.r .cell-code}\nsplit_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.75), seed = 42)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\n# Set the target and predictors\ny <- \"product_backorder\"\nx <- setdiff(names(train_h2o), y)\n\nautoml_models_h2o <- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 120,\n  nfolds            = 5,\n  stopping_metric = \"mae\", stopping_rounds = 3,\n  stopping_tolerance = 1e-2\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   2%\n13:41:49.764: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n13:41:49.782: AutoML: XGBoost is not available; skipping it.\n13:41:49.821: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:41:49.821: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n13:41:51.899: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:41:51.900: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |=====                                                                 |   8%\n13:41:59.601: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:41:59.601: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |=======                                                               |  10%\n13:42:01.985: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:42:01.985: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |=========                                                             |  13%\n13:42:05.731: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:42:05.731: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===========                                                           |  15%\n13:42:07.669: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:42:07.669: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |============                                                          |  17%\n13:42:09.482: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:42:09.482: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n13:42:11.557: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:42:11.557: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n13:42:12.130: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:42:12.130: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |==============                                                        |  20%\n13:42:12.736: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:42:12.736: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===============                                                       |  22%\n13:42:16.252: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:42:16.252: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |=================                                                     |  24%\n13:42:17.922: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:42:17.922: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n13:42:20.630: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:42:20.630: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |====================                                                  |  28%\n13:42:21.356: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:42:21.356: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |==========================================                            |  61%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |===============================================                       |  68%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |========================================================              |  79%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |===============================================================       |  89%\n13:43:38.339: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:43:38.339: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |================================================================      |  92%\n13:43:38.904: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:43:38.904: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===================================================================   |  95%\n  |                                                                            \n  |======================================================================| 100%\n13:43:49.750: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n13:43:49.750: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n```\n\n\n:::\n\n```{.r .cell-code}\n## View the leaderboard\nautoml_models_h2o@leaderboard \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                                 model_id      rmse        mse\n1    StackedEnsemble_AllModels_3_AutoML_1_20240624_134149 0.2289137 0.05240149\n2 StackedEnsemble_BestOfFamily_4_AutoML_1_20240624_134149 0.2295750 0.05270470\n3 StackedEnsemble_BestOfFamily_5_AutoML_1_20240624_134149 0.2295908 0.05271193\n4    StackedEnsemble_AllModels_2_AutoML_1_20240624_134149 0.2301453 0.05296688\n5 StackedEnsemble_BestOfFamily_3_AutoML_1_20240624_134149 0.2303951 0.05308192\n6            GBM_grid_1_AutoML_1_20240624_134149_model_24 0.2329332 0.05425786\n        mae     rmsle mean_residual_deviance\n1 0.1216883 0.1610961             0.05240149\n2 0.1212216 0.1615769             0.05270470\n3 0.1212092 0.1615464             0.05271193\n4 0.1237540 0.1621066             0.05296688\n5 0.1226309 0.1621706             0.05308192\n6 0.1241311 0.1634285             0.05425786\n\n[58 rows x 6 columns] \n```\n\n\n:::\n\n```{.r .cell-code}\nextract_h2o_model_name_by_position <- function(h2o_leaderboard, n = 1, verbose = T) {\n  \n  model_name <- h2o_leaderboard %>%\n    as.tibble() %>%\n    slice_(n) %>%\n    pull(model_id)\n  \n  if (verbose) message(model_name)\n  \n  return(model_name)\n  \n}\n\n## Predicting using Leader Model\nbest_model <- automl_models_h2o@leaderboard %>% \n  extract_h2o_model_name_by_position(1) %>% \n  h2o.getModel()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: `slice_()` was deprecated in dplyr 0.7.0.\nℹ Please use `slice()` instead.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: `as.tibble()` was deprecated in tibble 2.0.0.\nℹ Please use `as_tibble()` instead.\nℹ The signature and semantics have changed, see `?as_tibble`.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nStackedEnsemble_AllModels_3_AutoML_1_20240624_134149\n```\n\n\n:::\n\n```{.r .cell-code}\npredictions <- h2o.predict(best_model, newdata = as.h2o(test_tbl))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\ntypeof(predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"environment\"\n```\n\n\n:::\n\n```{.r .cell-code}\npredictions_tbl <- predictions %>% as_tibble()\nglimpse(predictions_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 4,764\nColumns: 1\n$ predict <dbl> 0.81931541, 0.56076219, 0.03329996, 0.76407596, 0.58963089, 0.…\n```\n\n\n:::\n\n```{.r .cell-code}\n## Save the leader model\nbest_model %>% h2o.saveModel(path = \"StackedEnsemble_AllModels_AutoML_20220603_533865\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"C:\\\\Users\\\\risho\\\\OneDrive\\\\Desktop\\\\internship_sparks\\\\ss24-bdml-rishon1234\\\\ML\\\\StackedEnsemble_AllModels_AutoML_20220603_533865\\\\StackedEnsemble_AllModels_3_AutoML_1_20240624_134149\"\n```\n\n\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}