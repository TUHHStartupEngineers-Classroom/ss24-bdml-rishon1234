[
  {
    "objectID": "ML/04_Performance_Measures.html",
    "href": "ML/04_Performance_Measures.html",
    "title": "04 Performance Measures",
    "section": "",
    "text": "library(h2o)\n\nlibrary(h2o)\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(rsample)\nlibrary(recipes)\nlibrary(h2o)\nh2o.init()\n\n Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         1 hours 8 minutes \n    H2O cluster timezone:       Europe/Berlin \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.44.0.3 \n    H2O cluster version age:    6 months and 1 day \n    H2O cluster name:           H2O_started_from_R_risho_wae888 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   0.86 GB \n    H2O cluster total cores:    12 \n    H2O cluster allowed cores:  12 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.4.0 (2024-04-24 ucrt) \n\n\nWarning in h2o.clusterInfo(): \nYour H2O cluster version is (6 months and 1 day) old. There may be a newer version available.\nPlease download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n\nproduct_backorders_tbl  &lt;- read_csv(\"C:/Users/risho/OneDrive/Desktop/internship_sparks/ss24-bdml-rishon1234/ML/data/Business Decisions with Machine Learning/product_backorders.csv\")\n\nRows: 19053 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\ndbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nproduct_backorders_tbl &lt;- product_backorders_tbl  %&gt;%\n  mutate_if(is.character, as.factor)\nset.seed(seed = 1113)\nsplit_obj                       &lt;- rsample::initial_split(product_backorders_tbl, prop = 0.85)\ntrain_readable_tbl              &lt;- training(split_obj)\ntest_readable_tbl               &lt;- testing(split_obj)\nrecipe_obj &lt;- recipe(went_on_backorder ~., data = train_readable_tbl) %&gt;% \n  step_zv(all_predictors()) %&gt;% \n  prep()\ntrain_tbl &lt;- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl  &lt;- bake(recipe_obj, new_data = test_readable_tbl)\n# Modeling\nh2o.init()\n\n Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         1 hours 8 minutes \n    H2O cluster timezone:       Europe/Berlin \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.44.0.3 \n    H2O cluster version age:    6 months and 1 day \n    H2O cluster name:           H2O_started_from_R_risho_wae888 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   0.86 GB \n    H2O cluster total cores:    12 \n    H2O cluster allowed cores:  12 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.4.0 (2024-04-24 ucrt) \n\n\nWarning in h2o.clusterInfo(): \nYour H2O cluster version is (6 months and 1 day) old. There may be a newer version available.\nPlease download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n\n# Split data into a training and a validation data frame\n# Setting the seed is just for reproducability\nsplit_h2o &lt;- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\ntrain_h2o &lt;- split_h2o[[1]]\nvalid_h2o &lt;- split_h2o[[2]]\ntest_h2o  &lt;- as.h2o(test_tbl)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n# Set the target and predictors\ny &lt;- \"went_on_backorder\"\nx &lt;- setdiff(names(train_h2o), y)\nautoml_models_h2o &lt;- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 30,\n  nfolds            = 5 \n)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |===                                                                   |   4%\n16:15:46.900: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n16:15:46.909: AutoML: XGBoost is not available; skipping it.\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=======================                                               |  32%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |=================================================                     |  71%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |======================================================================| 100%\n\nautoml_models_h2o@leaderboard\n\n                                                 model_id       auc   logloss\n1 StackedEnsemble_BestOfFamily_2_AutoML_9_20240622_161546 0.9503068 0.1761294\n2                          GBM_3_AutoML_9_20240622_161546 0.9501437 0.1775413\n3    StackedEnsemble_AllModels_1_AutoML_9_20240622_161546 0.9499032 0.1750447\n4    StackedEnsemble_AllModels_2_AutoML_9_20240622_161546 0.9497824 0.1752158\n5 StackedEnsemble_BestOfFamily_3_AutoML_9_20240622_161546 0.9495708 0.1765456\n6                          GBM_4_AutoML_9_20240622_161546 0.9474958 0.1793540\n      aucpr mean_per_class_error      rmse        mse\n1 0.7429323            0.1397014 0.2303083 0.05304193\n2 0.7422403            0.1246612 0.2310781 0.05339707\n3 0.7466137            0.1520485 0.2295476 0.05269212\n4 0.7419350            0.1624068 0.2293595 0.05260576\n5 0.7386264            0.1318523 0.2301580 0.05297270\n6 0.7352168            0.1638603 0.2315195 0.05360130\n\n[14 rows x 7 columns] \n\n# Visualize the H2O leaderboard to help with model selection\ndata_transformed_tbl &lt;- automl_models_h2o@leaderboard %&gt;%\n  as_tibble() %&gt;%\n  select(-c(aucpr, mean_per_class_error, rmse, mse)) %&gt;% \n  mutate(model_type = str_extract(model_id, \"[^_]+\")) %&gt;%\n  slice(1:15) %&gt;% \n  rownames_to_column(var = \"rowname\") %&gt;%\n  # Visually this step will not change anything\n  # It reorders the factors under the hood\n  mutate(\n    model_id   = as_factor(model_id) %&gt;% reorder(auc),\n    model_type = as.factor(model_type)\n  ) %&gt;% \n  pivot_longer(cols = -c(model_id, model_type, rowname), \n               names_to = \"key\", \n               values_to = \"value\", \n               names_transform = list(key = forcats::fct_inorder)\n  ) %&gt;% \n  mutate(model_id = paste0(rowname, \". \", model_id) %&gt;% as_factor() %&gt;% fct_rev())\ndata_transformed_tbl %&gt;%\n  ggplot(aes(value, model_id, color = model_type)) +\n  geom_point(size = 3) +\n  geom_label(aes(label = round(value, 2), hjust = \"inward\")) +\n  \n  # Facet to break out logloss and auc\n  facet_wrap(~ key, scales = \"free_x\") +\n  labs(title = \"Leaderboard Metrics\",\n       subtitle = paste0(\"Ordered by: \", \"auc\"),\n       y = \"Model Postion, Model ID\", x = \"\") + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\ndeeplearning_grid_01 &lt;- h2o.grid(\n  \n  # See help page for available algos\n  algorithm = \"deeplearning\",\n  \n  # I just use the same as the object\n  grid_id = \"deeplearning_grid_01\",\n  \n  # The following is for ?h2o.deeplearning()\n  # predictor and response variables\n  x = x,\n  y = y,\n  \n  # training and validation frame and crossfold validation\n  training_frame   = train_h2o,\n  validation_frame = valid_h2o,\n  nfolds = 5,\n  \n  # Hyperparamters: Use deeplearning_h2o@allparameters to see all\n  hyper_params = list(\n    # Use some combinations (the first one was the original)\n    hidden = list(c(10, 10, 10), c(50, 20, 10), c(20, 20, 20)),\n    epochs = c(10, 50, 100)\n  )\n)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\ngrid &lt;- h2o.getGrid(grid_id = \"deeplearning_grid_01\", sort_by = \"auc\", decreasing = TRUE)\ndeeplearning_grid_01_model_1 &lt;- h2o.getModel(grid@model_ids[[1]])\ndeeplearning_grid_01_model_1 %&gt;% h2o.auc(train = T, valid = T, xval = T)\n\n    train     valid      xval \n0.9262296 0.9053388 0.9044612 \n\ndeeplearning_grid_01_model_1 %&gt;%\n  h2o.performance(newdata = as.h2o(test_tbl))\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n\nH2OBinomialMetrics: deeplearning\n\nMSE:  0.07009478\nRMSE:  0.2647542\nLogLoss:  0.2518021\nMean Per-Class Error:  0.2098354\nAUC:  0.8943538\nAUCPR:  0.5755567\nGini:  0.7887077\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n         No Yes    Error       Rate\nNo     2314 200 0.079554  =200/2514\nYes     117 227 0.340116   =117/344\nTotals 2431 427 0.110917  =317/2858\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold       value idx\n1                       max f1  0.247794    0.588846 205\n2                       max f2  0.155253    0.668380 252\n3                 max f0point5  0.460318    0.632669 125\n4                 max accuracy  0.460318    0.911127 125\n5                max precision  0.902144    0.850000  13\n6                   max recall  0.000031    1.000000 399\n7              max specificity  0.995766    0.999602   0\n8             max absolute_mcc  0.410153    0.540630 145\n9   max min_per_class_accuracy  0.102906    0.813842 289\n10 max mean_per_class_accuracy  0.155253    0.816451 252\n11                     max tns  0.995766 2513.000000   0\n12                     max fns  0.995766  344.000000   0\n13                     max fps  0.000031 2514.000000 399\n14                     max tps  0.000031  344.000000 399\n15                     max tnr  0.995766    0.999602   0\n16                     max fnr  0.995766    1.000000   0\n17                     max fpr  0.000031    1.000000 399\n18                     max tpr  0.000031    1.000000 399\n\nGains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`\n\ntheme_new &lt;- theme(\n  legend.position  = \"bottom\",\n  legend.key       = element_blank(),\n  panel.background = element_rect(fill   = \"transparent\"),\n  panel.border     = element_rect(color = \"#FF0000\", fill = NA, size = 0.5),\n  panel.grid.major = element_line(color = \"#800000\", size = 0.333)\n) \n\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\nextract_h2o_model_name_by_position &lt;- function(h2o_leaderboard, n = 1, verbose = T) {\n  \n  model_name &lt;- h2o_leaderboard %&gt;%\n    as.tibble() %&gt;%\n    slice(n) %&gt;%\n    pull(model_id)\n  \n  if (verbose) message(model_name)\n  \n  return(model_name)\n  \n}\nextract_model &lt;- automl_models_h2o@leaderboard %&gt;% \n  extract_h2o_model_name_by_position(1)%&gt;% \n  h2o.getModel()\n\nWarning: `as.tibble()` was deprecated in tibble 2.0.0.\nℹ Please use `as_tibble()` instead.\nℹ The signature and semantics have changed, see `?as_tibble`.\n\n\nStackedEnsemble_BestOfFamily_2_AutoML_9_20240622_161546\n\nperformance_h2o &lt;- h2o.performance(extract_model, newdata = as.h2o(test_tbl))\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\nperformance_tbl &lt;- performance_h2o %&gt;%\n  h2o.metric() %&gt;%\n  as.tibble() \nperformance_tbl %&gt;%\n  filter(f1 == max(f1))\n\n# A tibble: 1 × 20\n  threshold    f1    f2 f0point5 accuracy precision recall specificity\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt;\n1     0.256 0.706 0.748    0.669    0.922     0.646  0.779       0.942\n# ℹ 12 more variables: absolute_mcc &lt;dbl&gt;, min_per_class_accuracy &lt;dbl&gt;,\n#   mean_per_class_accuracy &lt;dbl&gt;, tns &lt;dbl&gt;, fns &lt;dbl&gt;, fps &lt;dbl&gt;, tps &lt;dbl&gt;,\n#   tnr &lt;dbl&gt;, fnr &lt;dbl&gt;, fpr &lt;dbl&gt;, tpr &lt;dbl&gt;, idx &lt;int&gt;\n\nperformance_tbl %&gt;%\n  ggplot(aes(x = threshold)) +\n  geom_line(aes(y = precision), color = \"#FFFF00\", size = 1) +\n  geom_line(aes(y = recall), color = \"#808000\", size = 1) +\n  \n  # Insert line where precision and recall are harmonically optimized\n  geom_vline(xintercept = h2o.find_threshold_by_max_metric(performance_h2o, \"f1\")) +\n  labs(title = \"Precision vs Recall\", y = \"value\") +\n  theme_new\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nload_model_performance_metrics &lt;- function(model_id, test_tbl) {\n  \n  model_h2o &lt;- h2o.getModel(model_id)\n  perf_h2o  &lt;- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n  \n  perf_h2o %&gt;%\n    h2o.metric() %&gt;%\n    as_tibble() %&gt;%\n    mutate(auc = h2o.auc(perf_h2o)) %&gt;%\n    select(tpr, fpr, auc)\n  \n}\nleaderboard_tbl &lt;- automl_models_h2o@leaderboard %&gt;%\n  as_tibble() %&gt;%\n  slice(1:3)\nmodel_metrics_tbl &lt;- leaderboard_tbl %&gt;%\n  mutate(metrics = map(model_id, load_model_performance_metrics, test_tbl)) %&gt;%\n  rename(AUC = auc) %&gt;%\n  unnest(cols = metrics)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\nmodel_metrics_tbl %&gt;%\n  mutate(\n    \n    auc  = auc %&gt;%  as.character() %&gt;% as_factor()\n  ) %&gt;%\n  ggplot(aes(fpr, tpr, color = model_id, linetype = auc)) +\n  geom_line(size = 1) +\n  \n  # just for demonstration purposes\n  geom_abline(color = \"#FF00FF\", linetype = \"dotted\") +\n  \n  theme_new +\n  theme(\n    legend.direction = \"vertical\",\n  ) +\n  labs(\n    title = \"ROC Plot\",\n    subtitle = \"Performance of 3 Top Performing Models\"\n  )\n\n\n\n\n\n\n\nget_model_performance_metrics_recall_precision &lt;- function(model_id, test_tbl) {\n  \n  model_h2o &lt;- h2o.getModel(model_id)\n  perf_h2o  &lt;- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n  \n  perf_h2o %&gt;%\n    h2o.metric() %&gt;%\n    as_tibble() %&gt;%\n    mutate(auc = h2o.auc(perf_h2o)) %&gt;%\n    select(tpr, fpr, auc, precision, recall)\n}\nmodel_metrics_pre_recall_tbl &lt;- leaderboard_tbl %&gt;%\n  mutate(metrics = map(model_id, get_model_performance_metrics_recall_precision, test_tbl)) %&gt;%\n  rename(AUC = auc) %&gt;%\n  unnest(cols = metrics)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\nmodel_metrics_pre_recall_tbl %&gt;%\n  mutate(\n    auc  = auc %&gt;%  as.character() %&gt;% as_factor()\n  ) %&gt;%\n  ggplot(aes(recall, precision, color = model_id, linetype = auc)) +\n  geom_line(size = 1) +\n  theme_new + \n  theme(\n    legend.direction = \"vertical\",\n  ) +\n  labs(\n    title = \"Precision vs Recall Plot\",\n    subtitle = \"Performance of 3 Top Performing Models\"\n  )\n\n\n\n\n\n\n\nperformance_h2o &lt;- h2o.performance(extract_model, newdata = as.h2o(test_tbl))\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\ngain_lift_tbl &lt;- performance_h2o %&gt;%\n  h2o.gainsLift() %&gt;%\n  as.tibble()\ngain_transformed_tbl &lt;- gain_lift_tbl %&gt;% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %&gt;%\n  select(-contains(\"lift\")) %&gt;%\n  mutate(baseline = cumulative_data_fraction) %&gt;%\n  rename(gain     = cumulative_capture_rate) %&gt;%\n  # prepare the data for the plotting (for the color and group aesthetics)\n  pivot_longer(cols = c(gain, baseline), values_to = \"value\", names_to = \"key\")\ngain_transformed_tbl %&gt;%\n  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n  geom_line(size = 1.5) +\n  labs(\n    title = \"Gain Chart\",\n    x = \"Cumulative Data Fraction\",\n    y = \"Gain\"\n  ) +\n  theme_new\n\n\n\n\n\n\n\nlift_transformed_tbl &lt;- gain_lift_tbl %&gt;% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %&gt;%\n  select(-contains(\"capture\")) %&gt;%\n  mutate(baseline = 1) %&gt;%\n  rename(lift = cumulative_lift) %&gt;%\n  pivot_longer(cols = c(lift, baseline), values_to = \"value\", names_to = \"key\")\nlift_transformed_tbl %&gt;%\n  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n  geom_line(size = 1.5) +\n  labs(\n    title = \"Lift Chart\",\n    x = \"Cumulative Data Fraction\",\n    y = \"Lift\"\n  ) +\n  theme_new\n\n\n\n\n\n\n\nlibrary(cowplot)\nlibrary(glue)\nplot_h2o_performance &lt;- function(h2o_leaderboard, newdata, order_by = c(\"auc\", \"logloss\"),\n                                 max_models = 3, size = 1.5) {\n  \n  # Inputs\n  \n  leaderboard_tbl &lt;- h2o_leaderboard %&gt;%\n    as_tibble() %&gt;%\n    slice(1:max_models)\n  \n  newdata_tbl &lt;- newdata %&gt;%\n    as_tibble()\n  \n  # Selecting the first, if nothing is provided\n  order_by      &lt;- tolower(order_by[[1]]) \n  \n  # Convert string stored in a variable to column name (symbol)\n  order_by_expr &lt;- rlang::sym(order_by)\n  \n  # Turn of the progress bars ( opposite h2o.show_progress())\n  h2o.no_progress()\n  \n  # 1. Model metrics\n  \n  get_model_performance_metrics &lt;- function(model_id, test_tbl) {\n    \n    model_h2o &lt;- h2o.getModel(model_id)\n    perf_h2o  &lt;- h2o.performance(model_h2o, newdata = as.h2o(test_tbl))\n    \n    perf_h2o %&gt;%\n      h2o.metric() %&gt;%\n      as.tibble() %&gt;%\n      select(threshold, tpr, fpr, precision, recall)\n    \n  }\n  \n  model_metrics_tbl &lt;- leaderboard_tbl %&gt;%\n    mutate(metrics = map(model_id, get_model_performance_metrics, newdata_tbl)) %&gt;%\n    unnest(cols = metrics) %&gt;%\n    mutate(\n      model_id = as_factor(model_id) %&gt;% \n        # programmatically reorder factors depending on order_by\n        fct_reorder(!! order_by_expr, \n                    .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n      auc      = auc %&gt;% \n        round(3) %&gt;% \n        as.character() %&gt;% \n        as_factor() %&gt;% \n        fct_reorder(as.numeric(model_id)),\n      logloss  = logloss %&gt;% \n        round(4) %&gt;% \n        as.character() %&gt;% \n        as_factor() %&gt;% \n        fct_reorder(as.numeric(model_id))\n    )\n  \n  \n  #1A. ROC Plot\n  \n  p1 &lt;- model_metrics_tbl %&gt;%\n    ggplot(aes(fpr, tpr, color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    theme_new +\n    labs(title = \"ROC\", x = \"FPR\", y = \"TPR\") +\n    theme(legend.direction = \"vertical\") \n  \n  \n  #1B. Precision vs Recall\n  \n  p2 &lt;- model_metrics_tbl %&gt;%\n    ggplot(aes(recall, precision, color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    theme_new +\n    labs(title = \"Precision Vs Recall\", x = \"Recall\", y = \"Precision\") +\n    theme(legend.position = \"none\") \n  \n  \n  # 2. Gain / Lift\n  \n  get_gain_lift &lt;- function(model_id, test_tbl) {\n    \n    model_h2o &lt;- h2o.getModel(model_id)\n    perf_h2o  &lt;- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n    \n    perf_h2o %&gt;%\n      h2o.gainsLift() %&gt;%\n      as.tibble() %&gt;%\n      select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift)\n    \n  }\n  \n  gain_lift_tbl &lt;- leaderboard_tbl %&gt;%\n    mutate(metrics = map(model_id, get_gain_lift, newdata_tbl)) %&gt;%\n    unnest(cols = metrics) %&gt;%\n    mutate(\n      model_id = as_factor(model_id) %&gt;% \n        fct_reorder(!! order_by_expr, \n                    .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n      auc  = auc %&gt;% \n        round(3) %&gt;% \n        as.character() %&gt;% \n        as_factor() %&gt;% \n        fct_reorder(as.numeric(model_id)),\n      logloss = logloss %&gt;% \n        round(4) %&gt;% \n        as.character() %&gt;% \n        as_factor() %&gt;% \n        fct_reorder(as.numeric(model_id))\n    ) %&gt;%\n    rename(\n      gain = cumulative_capture_rate,\n      lift = cumulative_lift\n    ) \n  \n  # 2A. Gain Plot\n  \n  p3 &lt;- gain_lift_tbl %&gt;%\n    ggplot(aes(cumulative_data_fraction, gain, \n               color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size,) +\n    geom_segment(x = 0, y = 0, xend = 1, yend = 1, \n                 color = \"#FF00FF\", size = size, linetype = \"dotted\") +\n    theme_new +\n    expand_limits(x = c(0, 1), y = c(0, 1)) +\n    labs(title = \"Gain\",\n         x = \"Cumulative Data Fraction\", y = \"Gain\") +\n    theme(legend.position = \"none\")\n  \n  # 2B. Lift Plot\n  \n  p4 &lt;- gain_lift_tbl %&gt;%\n    ggplot(aes(cumulative_data_fraction, lift, \n               color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    geom_segment(x = 0, y = 1, xend = 1, yend = 1, \n                 color = \"#800080\", size = size, linetype = \"dotted\") +\n    theme_new +\n    expand_limits(x = c(0, 1), y = c(0, 1)) +\n    labs(title = \"Lift\",\n         x = \"Cumulative Data Fraction\", y = \"Lift\") +\n    theme(legend.position = \"none\") \n  \n  \n  # Combine using cowplot\n  \n  # cowplot::get_legend extracts a legend from a ggplot object\n  p_legend &lt;- get_legend(p1)\n  # Remove legend from p1\n  p1 &lt;- p1 + theme(legend.position = \"none\")\n  \n  # cowplot::plt_grid() combines multiple ggplots into a single cowplot object\n  p &lt;- cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)\n  \n  # cowplot::ggdraw() sets up a drawing layer\n  p_title &lt;- ggdraw() + \n    \n    # cowplot::draw_label() draws text on a ggdraw layer / ggplot object\n    draw_label(\"H2O Model Metrics\", size = 18, fontface = \"bold\", \n               color = \"#00FFFF\")\n  \n  p_subtitle &lt;- ggdraw() + \n    draw_label(glue(\"Ordered by {toupper(order_by)}\"), size = 10,  \n               color = \"#FFFF00\")\n  \n  # Combine everything\n  ret &lt;- plot_grid(p_title, p_subtitle, p, p_legend, \n                   \n                   # Adjust the relative spacing, so that the legends always fits\n                   ncol = 1, rel_heights = c(0.05, 0.05, 1, 0.05 * max_models))\n  \n  h2o.show_progress()\n  \n  return(ret)\n  \n}\nautoml_models_h2o@leaderboard %&gt;%\n  plot_h2o_performance(newdata = test_tbl, order_by = \"auc\", \n                       size = 0.5, max_models = 3)\n\nWarning in get_plot_component(plot, \"guide-box\"): Multiple components found;\nreturning the first one. To return all, use `return_all = TRUE`."
  }
]